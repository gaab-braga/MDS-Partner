{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "168199c2",
   "metadata": {},
   "source": [
    "# üèÜ MktPartner: Democratizando a Ci√™ncia de Dados S√™nior para o Brasil\n",
    "\n",
    "### **O Problema: O Abismo da Intelig√™ncia de Dados**\n",
    "No Brasil, 99% das empresas s√£o MPEs (Micro e Pequenas Empresas). O lucro m√©dio de um microempreendedor gira em torno de **2 sal√°rios m√≠nimos**. Enquanto grandes corpora√ß√µes investem milh√µes em equipes de Data Science para otimizar cada centavo de marketing, o pequeno empres√°rio opera no \"feeling\".\n",
    "*   **A consequ√™ncia:** 29% fecham em 5 anos, muitas vezes por queimarem caixa em estrat√©gias erradas.\n",
    "*   **A barreira:** Contratar um Cientista de Dados S√™nior custa 10x o que eles ganham.\n",
    "\n",
    "### **A Solu√ß√£o: Agentes de IA como \"S√≥cios Fracionados\"**\n",
    "Este projeto constr√≥i o **MktPartner**, um Sistema Multi-Agente que atua como um Cientista de Dados e Estrategista S√™nior acess√≠vel.\n",
    "N√£o √© apenas um chatbot. √â uma **equipe completa** (Estat√≠stico, Auditor, Diretor Criativo, Estrategista) que:\n",
    "1.  **Audita Dados:** Garante que o dinheiro n√£o est√° indo para o ralo.\n",
    "2.  **Calcula Risco:** Usa estat√≠stica rigorosa (n√£o alucina√ß√£o) para validar testes A/B.\n",
    "3.  **Define Estrat√©gia:** Usa frameworks como RICE e RCA para priorizar o lucro.\n",
    "\n",
    "---\n",
    "**Arquitetura:** Google ADK + Gemini 2.0 Flash + Scipy/Pandas + Gradio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29383bae",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Fase 1: A Funda√ß√£o da Firma Virtual\n",
    "Para construir um escrit√≥rio de consultoria digital, precisamos das ferramentas certas. Aqui, instalamos o **Google ADK** (Agent Development Kit), que ser√° o c√©rebro dos nossos agentes, e bibliotecas de an√°lise de dados (`pandas`, `scipy`) que ser√£o suas calculadoras. Diferente de modelos puramente lingu√≠sticos, nossos agentes precisam de \"Hard Skills\" matem√°ticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4c84f4-3400-48a5-b5de-423703a53b94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T23:37:12.790832Z",
     "iopub.status.busy": "2025-11-24T23:37:12.790365Z",
     "iopub.status.idle": "2025-11-24T23:37:37.315289Z",
     "shell.execute_reply": "2025-11-24T23:37:37.314003Z",
     "shell.execute_reply.started": "2025-11-24T23:37:12.790804Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# C√©lula 1\n",
    "import sys\n",
    "print(f\"üêç Python: {sys.version}\")\n",
    "print(\"\\n[INFO] Installing dependencies...\\n\")\n",
    "\n",
    "!pip install -q google-adk>=1.18.0\n",
    "!pip install -q google-cloud-bigquery>=3.15.0\n",
    "!pip install -q scipy>=1.11.0 pandas>=2.1.0 numpy>=1.24.0\n",
    "!pip install -q gradio>=4.14.0\n",
    "!pip install -q matplotlib>=3.7.0 seaborn>=0.12.0\n",
    "\n",
    "print(\"\\n[OK] All dependencies installed! ‚úÖ\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e60ac3-506a-49bb-9c45-e70c44d1de10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T23:37:56.362893Z",
     "iopub.status.busy": "2025-11-24T23:37:56.362589Z",
     "iopub.status.idle": "2025-11-24T23:38:02.411228Z",
     "shell.execute_reply": "2025-11-24T23:38:02.409942Z",
     "shell.execute_reply.started": "2025-11-24T23:37:56.362867Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# C√©lula 2\n",
    "!pip install -q google-adk 2>/dev/null || echo \"Google ADK pode n√£o estar dispon√≠vel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4628dd80-807e-419c-9d5a-32d76ff4cdfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T23:38:02.414295Z",
     "iopub.status.busy": "2025-11-24T23:38:02.414027Z",
     "iopub.status.idle": "2025-11-24T23:38:07.725861Z",
     "shell.execute_reply": "2025-11-24T23:38:07.724839Z",
     "shell.execute_reply.started": "2025-11-24T23:38:02.414269Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# C√©lula 3\n",
    "!pip install -U langchain-google-genai\n",
    "!export GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e96bca1-a62a-4f4f-8ea7-e4b02aef63ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T23:38:07.727368Z",
     "iopub.status.busy": "2025-11-24T23:38:07.727045Z",
     "iopub.status.idle": "2025-11-24T23:38:13.398079Z",
     "shell.execute_reply": "2025-11-24T23:38:13.396831Z",
     "shell.execute_reply.started": "2025-11-24T23:38:07.727339Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# celula 4\n",
    "!pip install chromadb\n",
    "!export GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9fbe7f-ff17-4568-9bd4-011aa5d73f67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T23:38:13.400903Z",
     "iopub.status.busy": "2025-11-24T23:38:13.399844Z",
     "iopub.status.idle": "2025-11-24T23:38:17.391767Z",
     "shell.execute_reply": "2025-11-24T23:38:17.390057Z",
     "shell.execute_reply.started": "2025-11-24T23:38:13.400855Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# C√©lula 5\n",
    "!pip install -q duckduckgo-search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696a0a75",
   "metadata": {},
   "source": [
    "## üß∞ Fase 2: Equipando os Especialistas\n",
    "Um bom cientista de dados precisa de resili√™ncia e mem√≥ria. Aqui instalamos:\n",
    "*   **LangChain & ChromaDB (RAG):** Para que o agente tenha \"mem√≥ria de longo prazo\" (Playbooks de Marketing) e n√£o precise reaprender estrat√©gias b√°sicas a cada sess√£o.\n",
    "*   **Tenacity:** Para garantir que o sistema n√£o falhe se uma API oscilar (resili√™ncia empresarial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50570d2e-c51f-4c5b-8bca-e1f728c3985e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T23:38:17.393785Z",
     "iopub.status.busy": "2025-11-24T23:38:17.393344Z",
     "iopub.status.idle": "2025-11-24T23:38:21.796319Z",
     "shell.execute_reply": "2025-11-24T23:38:21.794858Z",
     "shell.execute_reply.started": "2025-11-24T23:38:17.393743Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# C√©lula 6\n",
    "!pip install -q chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294e0f87-e849-46d4-a1e8-601c7f2454c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T23:37:37.317590Z",
     "iopub.status.busy": "2025-11-24T23:37:37.317288Z",
     "iopub.status.idle": "2025-11-24T23:37:56.361270Z",
     "shell.execute_reply": "2025-11-24T23:37:56.359657Z",
     "shell.execute_reply.started": "2025-11-24T23:37:37.317563Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# C√©lula 7\n",
    "print(\"[INFO] Installing RAG and Resilience dependencies...\\n\")\n",
    "\n",
    "%pip install -q langchain>=0.1.0 langchain-google-genai>=0.0.6\n",
    "%pip install -q chromadb>=0.4.22\n",
    "%pip install -q tenacity>=8.2.3\n",
    "%pip install -q pydantic>=2.5.0\n",
    "\n",
    "print(\"[OK] RAG + Resilience dependencies installed! ‚úÖ\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0245d4bd-1101-490a-a193-cce8fa03ea37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T23:38:21.798363Z",
     "iopub.status.busy": "2025-11-24T23:38:21.797946Z",
     "iopub.status.idle": "2025-11-24T23:38:21.831959Z",
     "shell.execute_reply": "2025-11-24T23:38:21.830669Z",
     "shell.execute_reply.started": "2025-11-24T23:38:21.798323Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# CELL 8: IMPORTS ADAPTATIVOS\n",
    "# ====================================================================\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import tempfile\n",
    "import atexit\n",
    "import math\n",
    "import json\n",
    "import warnings\n",
    "import uuid\n",
    "import hashlib\n",
    "import time\n",
    "import asyncio\n",
    "from io import StringIO\n",
    "from functools import wraps\n",
    "from typing import Dict, Any, List, Optional, Tuple, Callable\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from datetime import datetime, timedelta\n",
    "from enum import Enum\n",
    "from duckduckgo_search import DDGS\n",
    "\n",
    "print(\"üîÑ Carregando depend√™ncias...\")\n",
    "\n",
    "# ============ B√ÅSICOS ============\n",
    "import os, sys, logging, json, warnings, time\n",
    "from typing import Dict, Any, List, Optional\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "\n",
    "# ============ DADOS ============\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# SciPy (opcional)\n",
    "try:\n",
    "    from scipy import stats\n",
    "    SCIPY_OK = True\n",
    "except:\n",
    "    SCIPY_OK = False\n",
    "    \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from PIL import Image\n",
    "\n",
    "# ============ BUSCA WEB ============\n",
    "try:\n",
    "    from duckduckgo_search import DDGS\n",
    "    DDGS_OK = True\n",
    "    print(\"‚úÖ DuckDuckGo Search\")\n",
    "except ImportError as e:\n",
    "    DDGS_OK = False\n",
    "    print(f\"‚ùå DuckDuckGo: {e}\")\n",
    "    class DDGS:\n",
    "        def text(self, *args, **kwargs): return []\n",
    "\n",
    "# ============ GOOGLE ADK ============\n",
    "try:\n",
    "    from google.adk.agents import Agent, SequentialAgent, ParallelAgent, LoopAgent\n",
    "    from google.adk.runners import InMemoryRunner\n",
    "    from google.adk.tools import AgentTool, FunctionTool\n",
    "    ADK_OK = True\n",
    "    print(\"‚úÖ Google ADK\")\n",
    "except ImportError:\n",
    "    ADK_OK = False\n",
    "    print(\"‚ùå Google ADK\")\n",
    "    class Agent: pass\n",
    "    class SequentialAgent: pass\n",
    "    class ParallelAgent: pass\n",
    "    class LoopAgent: pass\n",
    "    class InMemoryRunner: pass\n",
    "    class AgentTool: pass\n",
    "    class FunctionTool:\n",
    "        def __init__(self, func): self.func = func\n",
    "\n",
    "# ============ KAGGLE ============\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    SECRETS_OK = True\n",
    "    print(\"‚úÖ Kaggle Secrets\")\n",
    "except ImportError:\n",
    "    SECRETS_OK = False\n",
    "    print(\"‚ö†Ô∏è Kaggle Secrets n√£o dispon√≠vel\")\n",
    "    class UserSecretsClient:\n",
    "        @staticmethod\n",
    "        def get_secret(key): return os.getenv(key)\n",
    "\n",
    "# ============ LANGCHAIN ============\n",
    "try:\n",
    "    from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "    from langchain_core.documents import Document\n",
    "    LANGCHAIN_OK = True\n",
    "    print(\"‚úÖ LangChain Google GenAI\")\n",
    "except ImportError as e:\n",
    "    LANGCHAIN_OK = False\n",
    "    print(f\"‚ùå LangChain: {e}\")\n",
    "    class GoogleGenerativeAIEmbeddings:\n",
    "        def __init__(self, **kwargs): pass\n",
    "    class Document:\n",
    "        def __init__(self, page_content, metadata=None):\n",
    "            self.page_content = page_content\n",
    "            self.metadata = metadata or {}\n",
    "\n",
    "# Text splitter\n",
    "try:\n",
    "    from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "except:\n",
    "    try:\n",
    "        from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    except:\n",
    "        class RecursiveCharacterTextSplitter:\n",
    "            def __init__(self, **kwargs): pass\n",
    "            def split_text(self, text): return [text]\n",
    "\n",
    "# ChromaDB\n",
    "try:\n",
    "    from langchain_community.vectorstores import Chroma\n",
    "    CHROMA_OK = True\n",
    "    print(\"‚úÖ ChromaDB\")\n",
    "except:\n",
    "    try:\n",
    "        from langchain.vectorstores import Chroma\n",
    "        CHROMA_OK = True\n",
    "        print(\"‚úÖ ChromaDB (legacy)\")\n",
    "    except:\n",
    "        CHROMA_OK = False\n",
    "        print(\"‚ùå ChromaDB\")\n",
    "        class Chroma:\n",
    "            def __init__(self, **kwargs): pass\n",
    "\n",
    "# ============ OUTROS ============\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "try:\n",
    "    import gradio as gr\n",
    "    GRADIO_OK = True\n",
    "    print(\"‚úÖ Gradio\")\n",
    "except:\n",
    "    GRADIO_OK = False\n",
    "    gr = None\n",
    "\n",
    "# ============ CONFIG ============\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "bq_toolset = None\n",
    "BIGQUERY_ENABLED = False\n",
    "\n",
    "# ============ BUSCA WEB ============\n",
    "def search_web(query: str) -> str:\n",
    "    \"\"\"Busca web com DuckDuckGo\"\"\"\n",
    "    if not DDGS_OK:\n",
    "        return \"Busca n√£o dispon√≠vel\"\n",
    "    try:\n",
    "        results = DDGS().text(query, max_results=3)\n",
    "        if not results:\n",
    "            return \"Sem resultados\"\n",
    "        return \"\\n\\n\".join([\n",
    "            f\"**{r['title']}**\\n{r['href']}\\n{r['body']}\"\n",
    "            for r in results\n",
    "        ])\n",
    "    except Exception as e:\n",
    "        return f\"Erro: {e}\"\n",
    "\n",
    "google_search_tool = FunctionTool(search_web) if ADK_OK else search_web\n",
    "\n",
    "# ============ STATUS ============\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä STATUS DO AMBIENTE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Python: {sys.version.split()[0]}\")\n",
    "print(f\"NumPy: {np.__version__} | Pandas: {pd.__version__}\")\n",
    "print(f\"SciPy: {'‚úÖ' if SCIPY_OK else '‚ö†Ô∏è'}\")\n",
    "print(f\"Google ADK: {'‚úÖ' if ADK_OK else '‚ùå'}\")\n",
    "print(f\"LangChain: {'‚úÖ' if LANGCHAIN_OK else '‚ùå'}\")\n",
    "print(f\"ChromaDB: {'‚úÖ' if CHROMA_OK else '‚ùå'}\")\n",
    "print(f\"DuckDuckGo: {'‚úÖ' if DDGS_OK else '‚ùå'}\")\n",
    "print(f\"Gradio: {'‚úÖ' if GRADIO_OK else '‚ùå'}\")\n",
    "\n",
    "essentials = LANGCHAIN_OK and (DDGS_OK or not ADK_OK)\n",
    "print(f\"\\n{'‚úÖ PRONTO' if essentials else '‚ö†Ô∏è VERIFICAR DEPEND√äNCIAS'}\")\n",
    "print(\"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fcb984",
   "metadata": {},
   "source": [
    "## üîê Fase 3: Seguran√ßa e Confian√ßa\n",
    "Pequenas empresas morrem se tiverem vazamento de dados. Implementamos um **Gerenciador de Credenciais Seguro** que limpa chaves de API da mem√≥ria ap√≥s o uso. O sistema suporta integra√ß√£o opcional com **BigQuery**, permitindo que empresas que j√° cresceram um pouco conectem seus dados reais de forma robusta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c042162",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T23:38:21.833354Z",
     "iopub.status.busy": "2025-11-24T23:38:21.833016Z",
     "iopub.status.idle": "2025-11-24T23:38:22.111008Z",
     "shell.execute_reply": "2025-11-24T23:38:22.109957Z",
     "shell.execute_reply.started": "2025-11-24T23:38:21.833334Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# CELL 9: CONFIGURA√á√ÉO SEGURA DE CREDENCIAIS\n",
    "# ====================================================================\n",
    "\n",
    "class SecureCredentialsManager:\n",
    "    \"\"\"Gerenciador seguro de credenciais com limpeza autom√°tica.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.temp_files = []\n",
    "        atexit.register(self.cleanup)\n",
    "\n",
    "    def setup_gemini_key(self) -> bool:\n",
    "        \"\"\"Configura a API Key do Gemini de forma segura.\"\"\"\n",
    "        try:\n",
    "            api_key = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
    "            if not api_key or len(api_key) < 20:\n",
    "                raise ValueError(\"Invalid API key\")\n",
    "            os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
    "            os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"FALSE\"\n",
    "            logger.info(\"‚úÖ Gemini API configured\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå API key failed: {e}\")\n",
    "            print(\"\\n[ACTION] Add GOOGLE_API_KEY in Kaggle Secrets\")\n",
    "            return False\n",
    "\n",
    "    def setup_bigquery_credentials(self) -> tuple:\n",
    "        \"\"\"Configura credenciais do BigQuery de forma segura.\"\"\"\n",
    "        try:\n",
    "            creds = UserSecretsClient().get_secret(\"BIGQUERY_SERVICE_ACCOUNT_JSON\")\n",
    "            fd, path = tempfile.mkstemp(suffix='.json', prefix='bq_')\n",
    "            os.write(fd, creds.encode())\n",
    "            os.close(fd)\n",
    "            os.chmod(path, 0o600)\n",
    "            os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = path\n",
    "            self.temp_files.append(path)\n",
    "            logger.info(\"‚úÖ BigQuery configured\")\n",
    "            return True, path\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"‚ö†Ô∏è BigQuery not configured: {e}\")\n",
    "            return False, \"\"\n",
    "\n",
    "    def cleanup(self):\n",
    "        \"\"\"Remove arquivos tempor√°rios de credenciais.\"\"\"\n",
    "        for path in self.temp_files:\n",
    "            try:\n",
    "                if os.path.exists(path):\n",
    "                    os.unlink(path)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "# Inicializar gerenciador de credenciais\n",
    "creds_manager = SecureCredentialsManager()\n",
    "GEMINI_READY = creds_manager.setup_gemini_key()\n",
    "BIGQUERY_ENABLED, BQ_PATH = creds_manager.setup_bigquery_credentials()\n",
    "\n",
    "if not GEMINI_READY:\n",
    "    raise RuntimeError(\"Cannot proceed without API key\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"üîê Security Status:\")\n",
    "print(f\"  ‚úÖ Gemini: Configured\")\n",
    "print(f\"  {'‚úÖ' if BIGQUERY_ENABLED else '‚ö†Ô∏è'} BigQuery: {'Enabled' if BIGQUERY_ENABLED else 'Optional'}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b63379c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T23:38:22.114315Z",
     "iopub.status.busy": "2025-11-24T23:38:22.114047Z",
     "iopub.status.idle": "2025-11-24T23:38:22.124597Z",
     "shell.execute_reply": "2025-11-24T23:38:22.123647Z",
     "shell.execute_reply.started": "2025-11-24T23:38:22.114294Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# ====================================================================\n",
    "# CELL 10 : IMPORTS E CONFIGURA√á√ïES\n",
    "# ====================================================================\n",
    "\n",
    "\n",
    "if BIGQUERY_ENABLED:\n",
    "    try:\n",
    "        from google.adk.tools.bigquery import BigQueryToolset, BigQueryCredentialsConfig, BigQueryToolConfig, WriteMode\n",
    "        from google.oauth2 import service_account\n",
    "        credentials = service_account.Credentials.from_service_account_file(BQ_PATH)\n",
    "        creds_config = BigQueryCredentialsConfig(credentials=credentials)\n",
    "        tool_config = BigQueryToolConfig(write_mode=WriteMode.BLOCKED)\n",
    "        bq_toolset = BigQueryToolset(credentials_config=creds_config, bigquery_tool_config=tool_config)\n",
    "        if BQ_PATH and os.path.exists(BQ_PATH):\n",
    "            credentials = service_account.Credentials.from_service_account_file(BQ_PATH)\n",
    "            creds_config = BigQueryCredentialsConfig(credentials=credentials)\n",
    "            bq_toolset = BigQueryToolset(credentials_config=creds_config)\n",
    "            BIGQUERY_ENABLED = True\n",
    "            logger.info(\"‚úÖ BigQuery enabled\")\n",
    "        logger.info(\"‚úÖ BigQuery initialized\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"BigQuery init failed: {e}\")\n",
    "        BIGQUERY_ENABLED = False\n",
    "\n",
    "def search_web(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Realiza uma pesquisa na web para encontrar informa√ß√µes atualizadas.\n",
    "    Use para buscar dados de mercado, benchmarks ou conceitos recentes.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        results = DDGS().text(query, max_results=3)\n",
    "        if not results:\n",
    "            return \"Nenhum resultado encontrado.\"\n",
    "        return \"\\n\\n\".join([f\"Title: {r['title']}\\nLink: {r['href']}\\nSnippet: {r['body']}\" for r in results])\n",
    "    except Exception as e:\n",
    "        return f\"Erro na busca: {str(e)}\"\n",
    "\n",
    "\n",
    "google_search = FunctionTool(search_web)\n",
    "\n",
    "logger.info(\"‚úÖ Imports complete\")\n",
    "print(\"[OK] Environment ready! üöÄ\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1669f3c",
   "metadata": {},
   "source": [
    "## üõ°Ô∏è Fase 4: O Auditor Rigoroso (Guardrails)\n",
    "LLMs podem \"alucinar\" n√∫meros. Em finan√ßas e marketing, um zero a mais quebra a empresa.\n",
    "Criamos um **Framework de Valida√ß√£o (InputValidator)**. Se um agente tentar calcular uma taxa de convers√£o maior que 100% ou um ROAS negativo, o sistema bloqueia antes de apresentar ao usu√°rio. Isso garante confiabilidade profissional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dbe5e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T23:38:22.125729Z",
     "iopub.status.busy": "2025-11-24T23:38:22.125488Z",
     "iopub.status.idle": "2025-11-24T23:38:22.150042Z",
     "shell.execute_reply": "2025-11-24T23:38:22.149196Z",
     "shell.execute_reply.started": "2025-11-24T23:38:22.125710Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# ====================================================================\n",
    "# CELL 11: FRAMEWORK DE VALIDA√á√ÉO\n",
    "# ====================================================================\n",
    "\n",
    "class ValidationError(Exception):\n",
    "    \"\"\"Exce√ß√£o customizada para erros de valida√ß√£o de entrada.\"\"\"\n",
    "    pass\n",
    "\n",
    "class InputValidator:\n",
    "    \"\"\"Validador robusto de inputs para an√°lises estat√≠sticas.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def validate_probability(value: float, name: str):\n",
    "        \"\"\"Valida se um valor √© uma probabilidade v√°lida (0, 1).\"\"\"\n",
    "        if not isinstance(value, (int, float)):\n",
    "            raise ValidationError(f\"{name} must be numeric\")\n",
    "        if not 0 < value < 1:\n",
    "            raise ValidationError(f\"{name} must be in (0,1), got {value}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def validate_positive(value: float, name: str):\n",
    "        \"\"\"Valida se um valor √© positivo.\"\"\"\n",
    "        if not isinstance(value, (int, float)):\n",
    "            raise ValidationError(f\"{name} must be numeric\")\n",
    "        if value <= 0:\n",
    "            raise ValidationError(f\"{name} must be positive\")\n",
    "\n",
    "    @staticmethod\n",
    "    def validate_ab_test_inputs(ctrl_conv, ctrl_total, treat_conv, treat_total):\n",
    "        \"\"\"Valida inputs de teste A/B.\"\"\"\n",
    "        for val, name in [(ctrl_conv, \"control_conversions\"), (ctrl_total, \"control_total\"),\n",
    "                          (treat_conv, \"treatment_conversions\"), (treat_total, \"treatment_total\")]:\n",
    "            if not isinstance(val, int) or val < 0:\n",
    "                raise ValidationError(f\"{name} must be non-negative integer\")\n",
    "        if ctrl_total == 0 or treat_total == 0:\n",
    "            raise ValidationError(\"Total cannot be zero\")\n",
    "        if ctrl_conv > ctrl_total:\n",
    "            raise ValidationError(f\"Control conversions > total\")\n",
    "        if treat_conv > treat_total:\n",
    "            raise ValidationError(f\"Treatment conversions > total\")\n",
    "\n",
    "    @staticmethod\n",
    "    def validate_dataframe(df: pd.DataFrame, required_cols: List[str] = None):\n",
    "        \"\"\"Valida um DataFrame.\"\"\"\n",
    "        if df.empty:\n",
    "            raise ValidationError(\"DataFrame is empty\")\n",
    "        if required_cols:\n",
    "            missing = set(required_cols) - set(df.columns)\n",
    "            if missing:\n",
    "                raise ValidationError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "logger.info(\"‚úÖ Validation framework ready\")\n",
    "print(\"[OK] Input validation loaded!\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4c119f",
   "metadata": {},
   "source": [
    "## üß† Fase 5: O C√©rebro H√≠brido (RAG + Dados)\n",
    "Um Partner S√™nior n√£o olha apenas planilhas; ele tem experi√™ncia.\n",
    "Implementamos um **HybridRAG**:\n",
    "1.  **Mem√≥ria de Dados:** Indexa os CSVs da campanha do cliente.\n",
    "2.  **Mem√≥ria Estrat√©gica:** Carrega \"Playbooks\" validados (ex: \"O que fazer na Black Friday?\", \"Como corrigir CPA alto?\").\n",
    "Isso permite que o agente combine *dados do cliente* com *sabedoria de mercado*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rag_system_005c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T23:38:22.151308Z",
     "iopub.status.busy": "2025-11-24T23:38:22.151026Z",
     "iopub.status.idle": "2025-11-24T23:38:22.184198Z",
     "shell.execute_reply": "2025-11-24T23:38:22.182704Z",
     "shell.execute_reply.started": "2025-11-24T23:38:22.151279Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# CELL 12: RAG SYSTEM H√çBRIDO (DADOS + ESTRAT√âGIA)\n",
    "# ====================================================================\n",
    "\n",
    "class HybridRAG:\n",
    "    \"\"\"RAG system que combina an√°lise de dados com playbooks estrat√©gicos.\"\"\"\n",
    "    \n",
    "    def __init__(self, embedding_model: str = \"models/embedding-001\"):\n",
    "        self.embeddings = GoogleGenerativeAIEmbeddings(model=embedding_model)\n",
    "        self.data_store = None\n",
    "        self.persist_dir = tempfile.mkdtemp(prefix=\"chroma_\")\n",
    "        self.strategy_store = None\n",
    "        \n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "        \n",
    "        # Inicializar Playbooks Padr√£o (Sabedoria do Partner)\n",
    "        self._init_strategy_store()\n",
    "    \n",
    "    def _init_strategy_store(self):\n",
    "        \"\"\"Carrega estrat√©gias de marketing validadas.\"\"\"\n",
    "        playbooks = [\n",
    "            \"Se o CPA subir repentinamente (>20%), verifique primeiro se o CPM subiu (leil√£o) ou se a CVR caiu (criativo/site). Se foi CPM, reduza or√ßamento de Topo de Funil. Se foi CVR, revise tracking e criativos.\",\n",
    "            \"Para escalar campanhas PMax, n√£o aumente o budget mais de 20% a cada 3 dias para n√£o resetar o aprendizado da m√°quina.\",\n",
    "            \"Em per√≠odos de Black Friday, o foco deve mudar de Aquisi√ß√£o para Remarketing, pois o CPM de aquisi√ß√£o fica proibitivo.\",\n",
    "            \"Se a reten√ß√£o de coorte (Cohort Retention) cai no m√™s 1, o problema geralmente √© Onboarding ou Expectativa vs Realidade do produto.\",\n",
    "            \"Clientes do cluster 'Whales' (Alto Valor, Alta Frequ√™ncia) devem receber tratamento VIP e ofertas exclusivas de pr√©-lan√ßamento.\"\n",
    "        ]\n",
    "        docs = [Document(page_content=p, metadata={\"type\": \"playbook\"}) for p in playbooks]\n",
    "        try:\n",
    "            self.strategy_store = Chroma.from_documents(docs, self.embeddings, collection_name=\"marketing_strategy\")\n",
    "            logger.info(\"‚úÖ Strategic Playbooks indexed\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"‚ö†Ô∏è Strategy RAG init failed: {e}\")\n",
    "\n",
    "    def chunk_campaign_data(self, df: pd.DataFrame) -> List[Document]:\n",
    "        \"\"\"Cria chunks sem√¢nticos dos dados de campanha.\"\"\"\n",
    "        documents = []\n",
    "        if 'campaign_name' in df.columns:\n",
    "            for campaign, group in df.groupby('campaign_name'):\n",
    "                stats = [\n",
    "                    f\"Campaign: {campaign}\",\n",
    "                    f\"Period: {group['date'].min()} to {group['date'].max()}\",\n",
    "                    f\"Metrics: Cost={group['cost'].sum():.2f}, Conv={group['conversions'].sum()}\"\n",
    "                ]\n",
    "                documents.append(Document(page_content=\"\\n\".join(stats), metadata={'campaign': campaign}))\n",
    "        return documents\n",
    "    \n",
    "    def index_data(self, df: pd.DataFrame) -> bool:\n",
    "        \"\"\"Indexa os dados no vector store.\"\"\"\n",
    "        try:\n",
    "            documents = self.chunk_campaign_data(df)\n",
    "            self.data_store = Chroma.from_documents(documents, self.embeddings, collection_name=\"campaign_data_new\")\n",
    "            logger.info(f\"‚úÖ Indexed {len(documents)} data chunks\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå RAG indexing failed: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def retrieve_strategy(self, query: str, k: int = 2) -> str:\n",
    "        \"\"\"Busca conselhos estrat√©gicos aplic√°veis.\"\"\"\n",
    "        if not self.strategy_store: return \"\"\n",
    "        docs = self.strategy_store.similarity_search(query, k=k)\n",
    "        return \"\\n\".join([f\"PLAYBOOK TIP: {d.page_content}\" for d in docs])\n",
    "\n",
    "rag_system = HybridRAG()\n",
    "print(\"[OK] HybridRAG initialized (Data + Strategy)! \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567c5ae2",
   "metadata": {},
   "source": [
    "## üíæ Fase 6: Gest√£o de Clientes (Session Manager)\n",
    "Para atender m√∫ltiplas microempresas (ou sess√µes de aprendizado de j√∫nior), precisamos de isolamento. O **Session Manager** garante que os dados da \"Padaria do Jo√£o\" n√£o se misturem com a \"Loja de Roupas da Maria\", mantendo o estado da an√°lise e o hist√≥rico de conversas organizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "session_manager_005d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T23:38:22.186637Z",
     "iopub.status.busy": "2025-11-24T23:38:22.185472Z",
     "iopub.status.idle": "2025-11-24T23:38:22.208923Z",
     "shell.execute_reply": "2025-11-24T23:38:22.207849Z",
     "shell.execute_reply.started": "2025-11-24T23:38:22.186575Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# CELL 13: SESSION MANAGER E GEST√ÉO DE ESTADO\n",
    "# ====================================================================\n",
    "\n",
    "@dataclass\n",
    "class AnalysisSession:\n",
    "    \"\"\"Sess√£o de an√°lise com estado persistente.\"\"\"\n",
    "    session_id: str = field(default_factory=lambda: str(uuid.uuid4()))\n",
    "    created_at: datetime = field(default_factory=datetime.now)\n",
    "    csv_data: Optional[pd.DataFrame] = None\n",
    "    rag_indexed: bool = False\n",
    "    analysis_history: List[Dict] = field(default_factory=list)\n",
    "    metadata: Dict = field(default_factory=dict)\n",
    "    \n",
    "    def add_analysis(self, analysis_type: str, result: Dict):\n",
    "        \"\"\"Adiciona uma an√°lise ao hist√≥rico.\"\"\"\n",
    "        self.analysis_history.append({\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'type': analysis_type,\n",
    "            'result': result\n",
    "        })\n",
    "    \n",
    "    def get_context(self) -> str:\n",
    "        \"\"\"Retorna contexto da sess√£o para o LLM.\"\"\"\n",
    "        context = []\n",
    "        context.append(f\"Session ID: {self.session_id}\")\n",
    "        context.append(f\"Created: {self.created_at.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        \n",
    "        if self.csv_data is not None:\n",
    "            context.append(f\"CSV Data: {len(self.csv_data)} rows, {len(self.csv_data.columns)} columns\")\n",
    "            context.append(f\"Columns: {', '.join(self.csv_data.columns.tolist())}\")\n",
    "        \n",
    "        context.append(f\"RAG Indexed: {self.rag_indexed}\")\n",
    "        context.append(f\"Analysis History: {len(self.analysis_history)} analyses\")\n",
    "        \n",
    "        return \"\\n\".join(context)\n",
    "\n",
    "class SessionManager:\n",
    "    \"\"\"Gerenciador de sess√µes de an√°lise.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.sessions: Dict[str, AnalysisSession] = {}\n",
    "        self.current_session_id: Optional[str] = None\n",
    "    \n",
    "    def create_session(self) -> AnalysisSession:\n",
    "        \"\"\"Cria uma nova sess√£o.\"\"\"\n",
    "        session = AnalysisSession()\n",
    "        self.sessions[session.session_id] = session\n",
    "        self.current_session_id = session.session_id\n",
    "        logger.info(f\"‚úÖ Created session: {session.session_id}\")\n",
    "        return session\n",
    "    \n",
    "    def get_session(self, session_id: Optional[str] = None) -> Optional[AnalysisSession]:\n",
    "        \"\"\"Retorna uma sess√£o espec√≠fica ou a atual.\"\"\"\n",
    "        sid = session_id or self.current_session_id\n",
    "        return self.sessions.get(sid)\n",
    "    \n",
    "    def switch_session(self, session_id: str) -> bool:\n",
    "        \"\"\"Troca para outra sess√£o.\"\"\"\n",
    "        if session_id in self.sessions:\n",
    "            self.current_session_id = session_id\n",
    "            logger.info(f\"‚úÖ Switched to session: {session_id}\")\n",
    "            return True\n",
    "        logger.warning(f\"‚ö†Ô∏è Session not found: {session_id}\")\n",
    "        return False\n",
    "    \n",
    "    def list_sessions(self) -> List[Dict]:\n",
    "        \"\"\"Lista todas as sess√µes.\"\"\"\n",
    "        return [\n",
    "            {\n",
    "                'session_id': sid,\n",
    "                'created_at': session.created_at.isoformat(),\n",
    "                'has_data': session.csv_data is not None,\n",
    "                'analyses': len(session.analysis_history)\n",
    "            }\n",
    "            for sid, session in self.sessions.items()\n",
    "        ]\n",
    "\n",
    "# Inicializar gerenciador global\n",
    "session_manager = SessionManager()\n",
    "current_session = session_manager.create_session()\n",
    "\n",
    "logger.info(\"‚úÖ Session Manager ready\")\n",
    "print(f\"[OK] Session created: {current_session.session_id}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a00fc78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T23:38:22.210313Z",
     "iopub.status.busy": "2025-11-24T23:38:22.209969Z",
     "iopub.status.idle": "2025-11-24T23:38:22.238552Z",
     "shell.execute_reply": "2025-11-24T23:38:22.237201Z",
     "shell.execute_reply.started": "2025-11-24T23:38:22.210267Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# C√©lula 14\n",
    "# Session management utilities: Export / Reset / Search\n",
    "\n",
    "\n",
    "def export_session(session_id: Optional[str] = None, filename: str = \"session_export.json\") -> str:\n",
    "    \"\"\"Export the session state to a JSON file.\n",
    "    Exports: metadata, rag_indexed, analysis_history, current context and optional runner metrics.\n",
    "    Returns the filename written (or an error string prefixed by \"ERROR:\").\n",
    "    \"\"\"\n",
    "    try:\n",
    "        session = session_manager.get_session(session_id)\n",
    "        if session is None:\n",
    "            return \"ERROR: Session not found\"\n",
    "\n",
    "        export_data = {\n",
    "            \"session_id\": session.session_id,\n",
    "            \"created_at\": session.created_at.isoformat(),\n",
    "            \"rag_indexed\": session.rag_indexed,\n",
    "            \"metadata\": session.metadata,\n",
    "            \"analysis_history\": session.analysis_history,\n",
    "            \"context_summary\": session.get_context(),\n",
    "            \"rows\": len(session.csv_data) if session.csv_data is not None else None,\n",
    "            \"columns\": list(session.csv_data.columns) if session.csv_data is not None else None\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            # Try to include runner stats if available\n",
    "            if 'runner' in globals() and runner is not None:\n",
    "                export_data[\"runner_stats\"] = runner.get_stats()\n",
    "        except Exception:\n",
    "            # non-fatal\n",
    "            export_data[\"runner_stats\"] = {\"error\": \"failed to fetch runner stats\"}\n",
    "\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(export_data, f, indent=2, default=str)\n",
    "\n",
    "        logger.info(\"Session exported\", filename=filename, session_id=session.session_id)\n",
    "        return filename\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(\"Failed to export session\", error=str(e))\n",
    "        return f\"ERROR: {str(e)}\"\n",
    "\n",
    "\n",
    "def reset_session(session_id: Optional[str] = None, create_new: bool = True) -> str:\n",
    "    \"\"\"Reset a session: remove its state; optionally create a new session and return its id.\n",
    "\n",
    "    This is safe for production: cleans `session_manager` mapping, but does not delete historical JSON exports.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        sid = session_id or session_manager.current_session_id\n",
    "        if sid not in session_manager.sessions:\n",
    "            return \"ERROR: Session not found\"\n",
    "\n",
    "        # Backup: in-memory copy for debugging if needed\n",
    "        old = session_manager.sessions.pop(sid)\n",
    "        logger.info(\"Session popped\", session_id=sid)\n",
    "\n",
    "        # Make sure the current session id is reset\n",
    "        if session_manager.current_session_id == sid:\n",
    "            session_manager.current_session_id = None\n",
    "\n",
    "        if create_new:\n",
    "            new_session = session_manager.create_session()\n",
    "            logger.info(\"New session created\", session_id=new_session.session_id)\n",
    "            return new_session.session_id\n",
    "\n",
    "        return sid\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(\"Failed to reset session\", error=str(e))\n",
    "        return f\"ERROR: {str(e)}\"\n",
    "\n",
    "\n",
    "def search_analysis_history(keyword: str, session_id: Optional[str] = None) -> list:\n",
    "    \"\"\"Search the analysis history for a specific keyword (case-insensitive) and return matches.\"\"\"\n",
    "    try:\n",
    "        sid = session_id or session_manager.current_session_id\n",
    "        if sid not in session_manager.sessions:\n",
    "            return []\n",
    "\n",
    "        session = session_manager.sessions[sid]\n",
    "        results = []\n",
    "        lower = keyword.lower()\n",
    "        for i, entry in enumerate(session.analysis_history):\n",
    "            type_str = entry.get('type', '')\n",
    "            result_str = json.dumps(entry.get('result', {}))\n",
    "            if lower in type_str.lower() or lower in result_str.lower():\n",
    "                results.append({\n",
    "                    'index': i,\n",
    "                    'type': entry.get('type'),\n",
    "                    'timestamp': entry.get('timestamp'),\n",
    "                    'preview': result_str[:500]\n",
    "                })\n",
    "\n",
    "        logger.info(\"Search finished\", query=keyword, matches=len(results))\n",
    "        return results\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(\"Error searching analysis history\", error=str(e))\n",
    "        return []\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc90f5f",
   "metadata": {},
   "source": [
    "## ‚ö° Fase 7: Alta Disponibilidade (Resili√™ncia)\n",
    "Sistemas em produ√ß√£o falham. Implementamos padr√µes de engenharia de software avan√ßados:\n",
    "*   **Cache:** Para n√£o gastar tokens (dinheiro) respondendo a mesma pergunta duas vezes.\n",
    "*   **Circuit Breaker:** Se uma ferramenta externa falhar repetidamente, o sistema \"abre o circuito\" para evitar falhas em cascata, protegendo a experi√™ncia do usu√°rio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resilience_patterns_005e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T23:38:22.239991Z",
     "iopub.status.busy": "2025-11-24T23:38:22.239715Z",
     "iopub.status.idle": "2025-11-24T23:38:22.266961Z",
     "shell.execute_reply": "2025-11-24T23:38:22.265718Z",
     "shell.execute_reply.started": "2025-11-24T23:38:22.239969Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# CELL 15: CACHE E CIRCUIT BREAKER\n",
    "# ====================================================================\n",
    "\n",
    "class QueryCache:\n",
    "    \"\"\"Cache simples para queries e an√°lises.\"\"\"\n",
    "    \n",
    "    def __init__(self, ttl: int = 3600):\n",
    "        self.cache: Dict[str, tuple] = {}  # key -> (value, timestamp)\n",
    "        self.ttl = ttl\n",
    "        self.hits = 0\n",
    "        self.misses = 0\n",
    "    \n",
    "    def _hash_key(self, key: str) -> str:\n",
    "        \"\"\"Gera hash da chave.\"\"\"\n",
    "        return hashlib.sha256(key.encode()).hexdigest()[:16]\n",
    "    \n",
    "    def get(self, key: str) -> Optional[Any]:\n",
    "        \"\"\"Recupera valor do cache.\"\"\"\n",
    "        hashed = self._hash_key(key)\n",
    "        if hashed in self.cache:\n",
    "            value, timestamp = self.cache[hashed]\n",
    "            if time.time() - timestamp < self.ttl:\n",
    "                self.hits += 1\n",
    "                logger.debug(f\"‚úÖ Cache HIT: {key[:50]}...\")\n",
    "                return value\n",
    "            else:\n",
    "                del self.cache[hashed]\n",
    "        self.misses += 1\n",
    "        return None\n",
    "    \n",
    "    def set(self, key: str, value: Any):\n",
    "        \"\"\"Armazena valor no cache.\"\"\"\n",
    "        hashed = self._hash_key(key)\n",
    "        self.cache[hashed] = (value, time.time())\n",
    "        logger.debug(f\"üíæ Cached: {key[:50]}...\")\n",
    "    \n",
    "    def clear(self):\n",
    "        \"\"\"Limpa o cache.\"\"\"\n",
    "        self.cache.clear()\n",
    "        self.hits = 0\n",
    "        self.misses = 0\n",
    "        logger.info(\"üóëÔ∏è Cache cleared\")\n",
    "    \n",
    "    def stats(self) -> Dict:\n",
    "        \"\"\"Retorna estat√≠sticas do cache.\"\"\"\n",
    "        total = self.hits + self.misses\n",
    "        hit_rate = (self.hits / total * 100) if total > 0 else 0\n",
    "        return {\n",
    "            'hits': self.hits,\n",
    "            'misses': self.misses,\n",
    "            'hit_rate': f\"{hit_rate:.1f}%\",\n",
    "            'size': len(self.cache)\n",
    "        }\n",
    "\n",
    "class CircuitBreaker:\n",
    "    \"\"\"Circuit Breaker para proteger contra falhas em cascata.\"\"\"\n",
    "    \n",
    "    def __init__(self, failure_threshold: int = 5, timeout: int = 60):\n",
    "        self.failure_threshold = failure_threshold\n",
    "        self.timeout = timeout\n",
    "        self.failures = 0\n",
    "        self.last_failure_time = None\n",
    "        self.state = \"CLOSED\"  # CLOSED, OPEN, HALF_OPEN\n",
    "    \n",
    "    def call(self, func: Callable, *args, **kwargs) -> Any:\n",
    "        \"\"\"Executa fun√ß√£o com prote√ß√£o de circuit breaker.\"\"\"\n",
    "        if self.state == \"OPEN\":\n",
    "            if time.time() - self.last_failure_time > self.timeout:\n",
    "                self.state = \"HALF_OPEN\"\n",
    "                logger.info(\"üü° Circuit breaker: HALF_OPEN\")\n",
    "            else:\n",
    "                raise Exception(\"Circuit breaker is OPEN\")\n",
    "        \n",
    "        try:\n",
    "            result = func(*args, **kwargs)\n",
    "            if self.state == \"HALF_OPEN\":\n",
    "                self.state = \"CLOSED\"\n",
    "                self.failures = 0\n",
    "                logger.info(\"üü¢ Circuit breaker: CLOSED\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            self.failures += 1\n",
    "            self.last_failure_time = time.time()\n",
    "            if self.failures >= self.failure_threshold:\n",
    "                self.state = \"OPEN\"\n",
    "                logger.warning(f\"üî¥ Circuit breaker OPENED after {self.failures} failures\")\n",
    "            raise e\n",
    "\n",
    "# Inicializar sistemas de resili√™ncia\n",
    "query_cache = QueryCache()\n",
    "circuit_breaker = CircuitBreaker()\n",
    "\n",
    "logger.info(\"‚úÖ Resilience systems ready\")\n",
    "print(\"[OK] Cache and Circuit Breaker initialized!\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96085c82",
   "metadata": {},
   "source": [
    "## üìã Fase 8: Comunica√ß√£o Executiva (Structured Output)\n",
    "O microempreendedor n√£o tem tempo para ler textos vagos. Ele precisa de **Planos de A√ß√£o**.\n",
    "Usamos **Pydantic** para for√ßar os agentes a responderem em formatos estruturados:\n",
    "*   **RCAReport:** An√°lise de Causa Raiz.\n",
    "*   **InsightsReport:** Tabela priorizada com score RICE.\n",
    "*   **ExperimentPlan:** Design de teste A/B pronto para execu√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pydantic_models_005f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T23:38:22.268651Z",
     "iopub.status.busy": "2025-11-24T23:38:22.268137Z",
     "iopub.status.idle": "2025-11-24T23:38:22.326686Z",
     "shell.execute_reply": "2025-11-24T23:38:22.325597Z",
     "shell.execute_reply.started": "2025-11-24T23:38:22.268626Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# CELL 16: STRUCTURED OUTPUTS COM PYDANTIC\n",
    "# ====================================================================\n",
    "\n",
    "class Priority(str, Enum):\n",
    "    CRITICAL = \"CR√çTICA\"\n",
    "    HIGH = \"ALTA\"\n",
    "    MEDIUM = \"M√âDIA\"\n",
    "    LOW = \"BAIXA\"\n",
    "\n",
    "class Timeline(str, Enum):\n",
    "    IMMEDIATE = \"24h\"\n",
    "    SHORT = \"72h\"\n",
    "    MEDIUM = \"1-2 semanas\"\n",
    "    LONG = \"1 m√™s+\"\n",
    "\n",
    "class RootCause(BaseModel):\n",
    "    why_level: int = Field(description=\"N√≠vel do 5 Whys (1-5)\", ge=1, le=5)\n",
    "    question: str = Field(description=\"Pergunta 'Por que?'\")\n",
    "    answer: str = Field(description=\"Resposta identificada\")\n",
    "\n",
    "class ActionItem(BaseModel):\n",
    "    priority: Priority = Field(description=\"Prioridade da a√ß√£o\")\n",
    "    timeline: Timeline = Field(description=\"Timeline para execu√ß√£o\")\n",
    "    action: str = Field(description=\"Descri√ß√£o detalhada da a√ß√£o\")\n",
    "    expected_impact: str = Field(description=\"Impacto esperado (quantitativo se poss√≠vel)\")\n",
    "    owner: str = Field(description=\"Respons√°vel sugerido\")\n",
    "    dependencies: List[str] = Field(default_factory=list, description=\"Depend√™ncias\")\n",
    "\n",
    "class RCAReport(BaseModel):\n",
    "    problem_summary: str = Field(description=\"Resumo do problema em 1-2 frases\")\n",
    "    metrics_impacted: List[str] = Field(description=\"M√©tricas impactadas (CVR, CPA, CTR)\")\n",
    "    five_whys: List[RootCause] = Field(description=\"An√°lise completa dos 5 Whys\")\n",
    "    root_causes: List[str] = Field(description=\"Causas raiz identificadas\")\n",
    "    immediate_actions: List[ActionItem] = Field(description=\"A√ß√µes imediatas (24-72h)\")\n",
    "    structural_actions: List[ActionItem] = Field(description=\"A√ß√µes estruturais (longo prazo)\")\n",
    "    confidence_level: float = Field(description=\"Confian√ßa na an√°lise (0-1)\", ge=0, le=1)\n",
    "    data_quality_notes: str = Field(description=\"Notas sobre qualidade dos dados\")\n",
    "\n",
    "class RICEScore(BaseModel):\n",
    "    reach: int = Field(description=\"Pessoas/sess√µes impactadas em 30 dias\", gt=0)\n",
    "    impact: float = Field(description=\"Impacto: 0.25 (baixo), 0.5 (m√©dio), 1 (alto), 2 (muito alto)\", gt=0)\n",
    "    confidence: float = Field(description=\"Confian√ßa na estimativa (0-1)\", ge=0, le=1)\n",
    "    effort: int = Field(description=\"Esfor√ßo em homem-dia\", gt=0)\n",
    "    rice_score: float = Field(description=\"Score RICE: (R √ó I √ó C) / E\")\n",
    "\n",
    "class Opportunity(BaseModel):\n",
    "    name: str = Field(description=\"Nome curto e descritivo\")\n",
    "    description: str = Field(description=\"Descri√ß√£o em 2-3 frases\")\n",
    "    rice: RICEScore = Field(description=\"Score RICE detalhado\")\n",
    "    rationale: str = Field(description=\"Por que est√° ranqueada nesta posi√ß√£o\")\n",
    "\n",
    "class InsightsReport(BaseModel):\n",
    "    opportunities: List[Opportunity] = Field(description=\"Oportunidades ordenadas por RICE\")\n",
    "    action_plan_30_days: Dict[str, List[str]] = Field(\n",
    "        description=\"Plano de a√ß√£o dividido por semanas\",\n",
    "        default_factory=dict\n",
    "    )\n",
    "    key_insights: List[str] = Field(description=\"3-5 insights principais\")\n",
    "    risks_and_considerations: List[str] = Field(description=\"Riscos e considera√ß√µes\")\n",
    "\n",
    "class ExperimentPlan(BaseModel):\n",
    "    hypothesis: str = Field(description=\"Hip√≥tese clara e test√°vel\")\n",
    "    metric_primary: str = Field(description=\"M√©trica prim√°ria (CVR, CPA)\")\n",
    "    metrics_secondary: List[str] = Field(description=\"M√©tricas secund√°rias\")\n",
    "    sample_size_per_group: int = Field(description=\"Tamanho de amostra por grupo\", gt=0)\n",
    "    duration_days: int = Field(description=\"Dura√ß√£o estimada em dias\", gt=0)\n",
    "    mde: float = Field(description=\"Efeito m√≠nimo detect√°vel (MDE) em p.p.\", gt=0)\n",
    "    alpha: float = Field(description=\"N√≠vel de signific√¢ncia\", ge=0.01, le=0.1, default=0.05)\n",
    "    power: float = Field(description=\"Poder estat√≠stico\", ge=0.7, le=0.95, default=0.8)\n",
    "    control_description: str = Field(description=\"Descri√ß√£o do grupo controle\")\n",
    "    treatment_description: str = Field(description=\"Descri√ß√£o do grupo tratamento\")\n",
    "    success_criteria: List[str] = Field(description=\"Crit√©rios de sucesso\")\n",
    "    risks: List[str] = Field(description=\"Riscos identificados\")\n",
    "    rollout_plan: str = Field(description=\"Plano de rollout se bem-sucedido\")\n",
    "\n",
    "logger.info(\"‚úÖ Structured Output Models ready\")\n",
    "print(\"[OK] Pydantic models loaded!\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7c0220",
   "metadata": {},
   "source": [
    "## üßÆ Fase 9: A Caixa de Ferramentas (Math vs. Magic)\n",
    "**Este √© o cora√ß√£o t√©cnico do projeto.**\n",
    "Para evitar que o LLM \"invente\" matem√°tica, criamos o **AdvancedDataScienceToolkit**.\n",
    "Os agentes n√£o \"estimam\" signific√¢ncia estat√≠stica; eles chamam fun√ß√µes Python (`scipy.stats`) para calcular Testes T, Qui-Quadrado e Tamanhos de Amostra. Tamb√©m adicionamos:\n",
    "*   **Cohort Analysis:** Para entender reten√ß√£o (vital para SaaS e E-commerce).\n",
    "*   **Forecast:** Regress√£o linear simples para prever tend√™ncias de curto prazo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec118ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T23:38:22.328241Z",
     "iopub.status.busy": "2025-11-24T23:38:22.327911Z",
     "iopub.status.idle": "2025-11-24T23:38:22.388994Z",
     "shell.execute_reply": "2025-11-24T23:38:22.387961Z",
     "shell.execute_reply.started": "2025-11-24T23:38:22.328215Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# CELL 17: ADVANCED DATA SCIENCE TOOLKIT (FUS√ÉO: STATS + ML + COHORT)\n",
    "# ====================================================================\n",
    "\n",
    "# --- 1. Data Transfer Objects (DTOs) ---\n",
    "\n",
    "@dataclass\n",
    "class SampleSizeResult:\n",
    "    \"\"\"Resultado do c√°lculo de tamanho de amostra.\"\"\"\n",
    "    sample_size_per_group: int\n",
    "    total_sample_size: int\n",
    "    baseline_rate: float\n",
    "    target_rate: float\n",
    "    mde_percentage: float\n",
    "    mde_absolute: float\n",
    "    alpha: float\n",
    "    power: float\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"sample_size_per_group\": self.sample_size_per_group,\n",
    "            \"total_sample_size\": self.total_sample_size,\n",
    "            \"baseline_rate\": self.baseline_rate,\n",
    "            \"target_rate\": self.target_rate,\n",
    "            \"mde_percentage\": self.mde_percentage,\n",
    "            \"mde_absolute\": self.mde_absolute,\n",
    "            \"alpha\": self.alpha,\n",
    "            \"power\": self.power,\n",
    "            \"interpretation\": f\"Para detectar um MDE de {self.mde_percentage}pp com {self.power*100}% de poder, voc√™ precisa de {self.sample_size_per_group:,} amostras por grupo.\"\n",
    "        }\n",
    "\n",
    "@dataclass\n",
    "class SignificanceResult:\n",
    "    \"\"\"Resultado do teste de signific√¢ncia estat√≠stica.\"\"\"\n",
    "    control_rate: float\n",
    "    treatment_rate: float\n",
    "    uplift_relative_pct: float\n",
    "    uplift_absolute_pp: float\n",
    "    p_value: float\n",
    "    z_statistic: float\n",
    "    is_significant: bool\n",
    "    is_positive: bool\n",
    "    ci_95_lower: float\n",
    "    ci_95_upper: float\n",
    "    sample_sizes: Dict[str, int]\n",
    "\n",
    "    def to_dict(self):\n",
    "        if self.is_significant and self.is_positive:\n",
    "            recommendation = \"[‚úÖ SHIP IT] Impacto positivo significativo\"\n",
    "        elif self.is_significant and not self.is_positive:\n",
    "            recommendation = \"[üõë DO NOT SHIP] Impacto negativo significativo\"\n",
    "        else:\n",
    "            recommendation = \"[‚è≥ KEEP TESTING] Ainda n√£o significativo\"\n",
    "\n",
    "        return {\n",
    "            \"control_rate\": self.control_rate,\n",
    "            \"treatment_rate\": self.treatment_rate,\n",
    "            \"uplift_relative_percentage\": self.uplift_relative_pct,\n",
    "            \"uplift_absolute_pp\": self.uplift_absolute_pp,\n",
    "            \"p_value\": self.p_value,\n",
    "            \"z_statistic\": self.z_statistic,\n",
    "            \"is_significant\": bool(self.is_significant),\n",
    "            \"is_positive\": bool(self.is_positive),\n",
    "            \"confidence_interval_95\": {\n",
    "                \"lower\": self.ci_95_lower,\n",
    "                \"upper\": self.ci_95_upper,\n",
    "                \"lower_pp\": self.ci_95_lower * 100,\n",
    "                \"upper_pp\": self.ci_95_upper * 100\n",
    "            },\n",
    "            \"interpretation\": \"SIGNIFICATIVO (p < 0.05)\" if self.is_significant else \"N√ÉO SIGNIFICATIVO\",\n",
    "            \"recommendation\": recommendation,\n",
    "            \"sample_sizes\": self.sample_sizes\n",
    "        }\n",
    "\n",
    "@dataclass\n",
    "class EDAResult:\n",
    "    \"\"\"Resultado da an√°lise explorat√≥ria de dados.\"\"\"\n",
    "    shape: Dict[str, int]\n",
    "    columns: List[str]\n",
    "    dtypes: Dict[str, str]\n",
    "    missing_values: Dict[str, Dict[str, float]]\n",
    "    duplicate_rows: int\n",
    "    numeric_summary: Dict[str, Dict[str, float]]\n",
    "    categorical_summary: Dict[str, Dict[str, Any]]\n",
    "    outliers: Dict[str, List[float]]\n",
    "    correlations: Dict[str, float]\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"shape\": self.shape,\n",
    "            \"columns\": self.columns,\n",
    "            \"dtypes\": self.dtypes,\n",
    "            \"missing_values\": self.missing_values,\n",
    "            \"duplicate_rows\": self.duplicate_rows,\n",
    "            \"numeric_summary\": self.numeric_summary,\n",
    "            \"categorical_summary\": self.categorical_summary,\n",
    "            \"outliers\": self.outliers,\n",
    "            \"correlations\": self.correlations\n",
    "        }\n",
    "\n",
    "# --- 2. Toolkit Class Unified ---\n",
    "\n",
    "class AdvancedDataScienceToolkit:\n",
    "    \"\"\"Toolkit unificado: Estat√≠stica (Stats) + Preditiva (ML) + Comportamental (Cohort).\"\"\"\n",
    "\n",
    "    # --- M√ìDULO A: ESTAT√çSTICA (Sua implementa√ß√£o robusta) ---\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_sample_size(baseline_rate: float, mde: float, alpha=0.05, power=0.8) -> SampleSizeResult:\n",
    "        \"\"\"Calcula tamanho de amostra necess√°rio para teste A/B.\"\"\"\n",
    "        # Se InputValidator existir (c√©lula 4), usa. Se n√£o, try/except pass.\n",
    "        try:\n",
    "            InputValidator.validate_probability(baseline_rate, \"baseline_rate\")\n",
    "            InputValidator.validate_positive(mde, \"mde\")\n",
    "        except NameError: pass\n",
    "\n",
    "        p1 = baseline_rate\n",
    "        p2 = baseline_rate + (mde / 100)\n",
    "\n",
    "        if p2 >= 1.0: p2 = 0.99 # Cap para evitar erro matem√°tico\n",
    "\n",
    "        z_alpha = stats.norm.ppf(1 - alpha / 2)\n",
    "        z_beta = stats.norm.ppf(power)\n",
    "\n",
    "        numerator = (z_alpha + z_beta) ** 2 * (p1 * (1 - p1) + p2 * (1 - p2))\n",
    "        denominator = (p1 - p2) ** 2\n",
    "\n",
    "        n_per_group = math.ceil(numerator / denominator) if denominator > 0 else 0\n",
    "\n",
    "        return SampleSizeResult(\n",
    "            sample_size_per_group=n_per_group,\n",
    "            total_sample_size=n_per_group * 2,\n",
    "            baseline_rate=baseline_rate,\n",
    "            target_rate=p2,\n",
    "            mde_percentage=mde,\n",
    "            mde_absolute=p2 - p1,\n",
    "            alpha=alpha,\n",
    "            power=power\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_statistical_significance(\n",
    "        ctrl_conv: int, ctrl_total: int, \n",
    "        treat_conv: int, treat_total: int, \n",
    "        alpha: float = 0.05\n",
    "    ) -> SignificanceResult:\n",
    "        \"\"\"Calcula signific√¢ncia estat√≠stica de teste A/B usando teste Z.\"\"\"\n",
    "        try: InputValidator.validate_ab_test_inputs(ctrl_conv, ctrl_total, treat_conv, treat_total)\n",
    "        except NameError: pass\n",
    "\n",
    "        if ctrl_total == 0 or treat_total == 0:\n",
    "            raise ValueError(\"Total samples cannot be zero\")\n",
    "\n",
    "        p1 = ctrl_conv / ctrl_total\n",
    "        p2 = treat_conv / treat_total\n",
    "\n",
    "        p_pooled = (ctrl_conv + treat_conv) / (ctrl_total + treat_total)\n",
    "        se = math.sqrt(p_pooled * (1 - p_pooled) * (1/ctrl_total + 1/treat_total))\n",
    "\n",
    "        z = (p2 - p1) / se if se > 0 else 0\n",
    "        p_value = 2 * (1 - stats.norm.cdf(abs(z)))\n",
    "\n",
    "        uplift_relative = ((p2 - p1) / p1 * 100) if p1 > 0 else 0\n",
    "        uplift_absolute = (p2 - p1) * 100\n",
    "\n",
    "        se_diff = math.sqrt(p1 * (1 - p1) / ctrl_total + p2 * (1 - p2) / treat_total)\n",
    "        ci_margin = stats.norm.ppf(1 - alpha/2) * se_diff\n",
    "        ci_lower = p2 - p1 - ci_margin\n",
    "        ci_upper = p2 - p1 + ci_margin\n",
    "\n",
    "        return SignificanceResult(\n",
    "            control_rate=p1,\n",
    "            treatment_rate=p2,\n",
    "            uplift_relative_pct=uplift_relative,\n",
    "            uplift_absolute_pp=uplift_absolute,\n",
    "            p_value=p_value,\n",
    "            z_statistic=z,\n",
    "            is_significant=p_value < alpha,\n",
    "            is_positive=p2 > p1,\n",
    "            ci_95_lower=ci_lower,\n",
    "            ci_95_upper=ci_upper,\n",
    "            sample_sizes={\"control\": ctrl_total, \"treatment\": treat_total, \"total\": ctrl_total + treat_total}\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def perform_chi_square_test(contingency_table: List[List[int]]) -> Dict[str, Any]:\n",
    "        \"\"\"Executa teste qui-quadrado.\"\"\"\n",
    "        try:\n",
    "            chi2, p_value, dof, expected = stats.chi2_contingency(contingency_table, correction=False)\n",
    "            return {\n",
    "                \"test_type\": \"chi_square\",\n",
    "                \"p_value\": float(p_value),\n",
    "                \"is_significant\": bool(p_value < 0.05),\n",
    "                \"interpretation\": \"SIGNIFICATIVO (Associa√ß√£o detectada)\" if p_value < 0.05 else \"N√ÉO SIGNIFICATIVO\"\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "    @staticmethod\n",
    "    def perform_t_test(group_a: List[float], group_b: List[float]) -> Dict[str, Any]:\n",
    "        \"\"\"Executa teste t independente.\"\"\"\n",
    "        try:\n",
    "            t_stat, p_value = stats.ttest_ind(group_a, group_b, equal_var=False)\n",
    "            mean_a = np.mean(group_a)\n",
    "            mean_b = np.mean(group_b)\n",
    "            return {\n",
    "                \"test_type\": \"t_test\",\n",
    "                \"p_value\": float(p_value),\n",
    "                \"is_significant\": bool(p_value < 0.05),\n",
    "                \"diff_pct\": float((mean_b - mean_a) / mean_a * 100) if mean_a != 0 else 0\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "    @staticmethod\n",
    "    def analyze_csv_dataframe(csv_data: str) -> EDAResult:\n",
    "        \"\"\"An√°lise explorat√≥ria completa (EDA).\"\"\"\n",
    "        try:\n",
    "            df = pd.read_csv(StringIO(csv_data))\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Invalid CSV: {e}\"}\n",
    "\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        numeric_summary = {}\n",
    "        outliers = {}\n",
    "\n",
    "        for col in numeric_cols:\n",
    "            numeric_summary[col] = {\n",
    "                \"mean\": float(df[col].mean()),\n",
    "                \"median\": float(df[col].median()),\n",
    "                \"min\": float(df[col].min()),\n",
    "                \"max\": float(df[col].max())\n",
    "            }\n",
    "            # Simplificando outliers para performance\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            outliers[col] = df[col][(df[col] < Q1 - 1.5*(Q3-Q1)) | (df[col] > Q3 + 1.5*(Q3-Q1))].head(5).tolist()\n",
    "\n",
    "        categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "        categorical_summary = {col: {\"top\": df[col].value_counts().head(3).to_dict()} for col in categorical_cols}\n",
    "\n",
    "        missing = df.isnull().sum()\n",
    "        missing_summary = {col: float(missing[col]) for col in df.columns if missing[col] > 0}\n",
    "\n",
    "        return EDAResult(\n",
    "            shape={\"rows\": len(df), \"columns\": len(df.columns)},\n",
    "            columns=df.columns.tolist(),\n",
    "            dtypes={col: str(dtype) for col, dtype in df.dtypes.items()},\n",
    "            missing_values=missing_summary,\n",
    "            duplicate_rows=int(df.duplicated().sum()),\n",
    "            numeric_summary=numeric_summary,\n",
    "            categorical_summary=categorical_summary,\n",
    "            outliers=outliers,\n",
    "            correlations={} \n",
    "        )\n",
    "\n",
    "    # --- M√ìDULO B: PREDITIVA E CLUSTERING (Adicionado para suportar Agentes Avan√ßados) ---\n",
    "\n",
    "    @staticmethod\n",
    "    def forecast_metric(dates_json: str, values_json: str, days_ahead: int = 7) -> Dict:\n",
    "        \"\"\"Realiza previs√£o de s√©rie temporal simples (Regress√£o Linear).\"\"\"\n",
    "        try:\n",
    "            dates = json.loads(dates_json) if isinstance(dates_json, str) else dates_json\n",
    "            values = json.loads(values_json) if isinstance(values_json, str) else values_json\n",
    "            \n",
    "            if len(values) < 3: return {\"error\": \"Dados insuficientes para forecast (min 3 pontos)\"}\n",
    "            \n",
    "            X = np.array(range(len(values))).reshape(-1, 1)\n",
    "            y = np.array(values)\n",
    "            \n",
    "            model = LinearRegression()\n",
    "            model.fit(X, y)\n",
    "            r2 = model.score(X, y)\n",
    "            \n",
    "            future_X = np.array(range(len(values), len(values) + days_ahead)).reshape(-1, 1)\n",
    "            predictions = model.predict(future_X)\n",
    "            \n",
    "            return {\n",
    "                \"trend\": \"Crescente\" if model.coef_[0] > 0 else \"Decrescente\",\n",
    "                \"next_value\": round(predictions[0], 2),\n",
    "                \"forecast_7d\": np.round(predictions, 2).tolist(),\n",
    "                \"r2_score\": round(r2, 2),\n",
    "                \"reliability\": \"Alta\" if r2 > 0.7 else \"Baixa (Cuidado)\"\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "    @staticmethod\n",
    "    def segment_customers(rfm_json: str) -> Dict:\n",
    "        \"\"\"Segmenta clientes usando K-Means (RFM).\"\"\"\n",
    "        try:\n",
    "            data = json.loads(rfm_json)\n",
    "            df = pd.DataFrame(data)\n",
    "            required = {'recency', 'frequency', 'monetary'}\n",
    "            if not required.issubset(df.columns): return {\"error\": f\"Missing columns: {required}\"}\n",
    "            \n",
    "            # Simple heuristic implementation instead of full sklearn to avoid dependency if not installed\n",
    "            # (Assuming sklearn IS installed per Cell 1)\n",
    "            scaler = StandardScaler()\n",
    "            scaled = scaler.fit_transform(df[['recency', 'frequency', 'monetary']])\n",
    "            kmeans = KMeans(n_clusters=3, n_init=10, random_state=42)\n",
    "            df['cluster'] = kmeans.fit_predict(scaled)\n",
    "            \n",
    "            summary = df.groupby('cluster')[['recency', 'frequency', 'monetary']].mean().to_dict(orient='records')\n",
    "            return {\"clusters_summary\": summary, \"counts\": df['cluster'].value_counts().to_dict()}\n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "    @staticmethod\n",
    "    def analyze_cohort_retention(csv_data: str) -> Dict:\n",
    "        \"\"\"Analisa reten√ß√£o de coorte (Cohort Analysis).\"\"\"\n",
    "        try:\n",
    "            df = pd.read_csv(StringIO(csv_data))\n",
    "            if 'user_id' not in df.columns or 'date' not in df.columns:\n",
    "                return {\"status\": \"SKIPPED\", \"reason\": \"Missing user_id or date column\"}\n",
    "            \n",
    "            df['date'] = pd.to_datetime(df['date'])\n",
    "            # Definir m√™s de coorte (primeira apari√ß√£o)\n",
    "            df['cohort_month'] = df.groupby('user_id')['date'].transform('min').dt.to_period('M')\n",
    "            df['current_month'] = df['date'].dt.to_period('M')\n",
    "            \n",
    "            cohort_data = df.groupby(['cohort_month', 'current_month'])['user_id'].nunique().reset_index()\n",
    "            cohort_data['period_number'] = (cohort_data.current_month - cohort_data.cohort_month).apply(lambda x: x.n)\n",
    "            \n",
    "            cohort_pivot = cohort_data.pivot_table(index='cohort_month', columns='period_number', values='user_id')\n",
    "            cohort_size = cohort_pivot.iloc[:, 0]\n",
    "            retention = cohort_pivot.divide(cohort_size, axis=0)\n",
    "            \n",
    "            return {\n",
    "                \"retention_matrix\": retention.iloc[:, :4].fillna(0).applymap(lambda x: f\"{x:.1%}\").to_dict(),\n",
    "                \"insight\": \"Matriz de reten√ß√£o calculada com sucesso.\"\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Cohort failed: {str(e)}\"}\n",
    "\n",
    "# --- 3. Wrappers Seguros para os Agentes ---\n",
    "\n",
    "def safe_calculate_sample_size(baseline_rate, mde, alpha=0.05, power=0.8) -> str:\n",
    "    \"\"\"Calcula tamanho de amostra. Inputs: baseline_rate (0-1), mde (pp).\"\"\"\n",
    "    try:\n",
    "        res = AdvancedDataScienceToolkit.calculate_sample_size(float(baseline_rate), float(mde), float(alpha), float(power))\n",
    "        return json.dumps(res.to_dict(), indent=2)\n",
    "    except Exception as e: return json.dumps({\"error\": str(e)})\n",
    "\n",
    "def safe_calculate_significance(ctrl_conv, ctrl_total, treat_conv, treat_total) -> str:\n",
    "    \"\"\"Calcula signific√¢ncia estat√≠stica (Teste Z).\"\"\"\n",
    "    try:\n",
    "        res = AdvancedDataScienceToolkit.calculate_statistical_significance(int(ctrl_conv), int(ctrl_total), int(treat_conv), int(treat_total))\n",
    "        return json.dumps(res.to_dict(), indent=2)\n",
    "    except Exception as e: return json.dumps({\"error\": str(e)})\n",
    "\n",
    "def safe_analyze_csv(csv_data: str) -> str:\n",
    "    \"\"\"An√°lise explorat√≥ria de CSV.\"\"\"\n",
    "    try:\n",
    "        res = AdvancedDataScienceToolkit.analyze_csv_dataframe(csv_data)\n",
    "        if isinstance(res, dict) and \"error\" in res: return json.dumps(res)\n",
    "        return json.dumps(res.to_dict(), indent=2, default=str)\n",
    "    except Exception as e: return json.dumps({\"error\": str(e)})\n",
    "\n",
    "def safe_chi_square_test(contingency_table_json: str) -> str:\n",
    "    \"\"\"Teste Qui-Quadrado. Input: JSON string [[a,b],[c,d]].\"\"\"\n",
    "    try:\n",
    "        table = json.loads(contingency_table_json)\n",
    "        return json.dumps(AdvancedDataScienceToolkit.perform_chi_square_test(table), indent=2)\n",
    "    except Exception as e: return json.dumps({\"error\": str(e)})\n",
    "\n",
    "def safe_t_test(group_a_json: str, group_b_json: str) -> str:\n",
    "    \"\"\"Teste T. Input: JSON strings de listas num√©ricas.\"\"\"\n",
    "    try:\n",
    "        return json.dumps(AdvancedDataScienceToolkit.perform_t_test(json.loads(group_a_json), json.loads(group_b_json)), indent=2)\n",
    "    except Exception as e: return json.dumps({\"error\": str(e)})\n",
    "\n",
    "def safe_forecast(dates_json: str, values_json: str) -> str:\n",
    "    \"\"\"Forecast de m√©trica.\"\"\"\n",
    "    return json.dumps(AdvancedDataScienceToolkit.forecast_metric(dates_json, values_json))\n",
    "\n",
    "def safe_cohort(csv_data: str) -> str:\n",
    "    \"\"\"An√°lise de Cohort.\"\"\"\n",
    "    return json.dumps(AdvancedDataScienceToolkit.analyze_cohort_retention(csv_data))\n",
    "\n",
    "def safe_segmentation(rfm_json: str) -> str:\n",
    "    \"\"\"Segmenta√ß√£o de clientes.\"\"\"\n",
    "    return json.dumps(AdvancedDataScienceToolkit.segment_customers(rfm_json))\n",
    "\n",
    "# --- 4. Instancia√ß√£o das Ferramentas (FunctionTools) ---\n",
    "\n",
    "# Core Statistics\n",
    "sample_size_tool = FunctionTool(safe_calculate_sample_size)\n",
    "significance_tool = FunctionTool(safe_calculate_significance)\n",
    "csv_analysis_tool = FunctionTool(safe_analyze_csv)\n",
    "chi_square_tool = FunctionTool(safe_chi_square_test)\n",
    "t_test_tool = FunctionTool(safe_t_test)\n",
    "\n",
    "# Advanced DS (Novas ferramentas adicionadas)\n",
    "forecast_tool = FunctionTool(safe_forecast)\n",
    "cohort_tool = FunctionTool(safe_cohort)\n",
    "segmentation_tool = FunctionTool(safe_segmentation)\n",
    "\n",
    "# Alias para compatibilidade retroativa\n",
    "StatisticalToolkit = AdvancedDataScienceToolkit\n",
    "\n",
    "logger.info(\"‚úÖ Advanced Data Science Toolkit Ready (Stats + ML + Cohort)\")\n",
    "print(\"[OK] All Statistical & ML functions loaded and tools created! üß†\\\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64ffe4d",
   "metadata": {},
   "source": [
    "## ü§ñ Fase 10: Contratando o Time Operacional (Agentes N√≠vel 1)\n",
    "Aqui instanciamos os especialistas que far√£o o trabalho pesado. Cada agente tem uma \"Instruction\" (System Prompt) otimizada para atuar como um profissional espec√≠fico:\n",
    "*   **DataQualityAgent:** O Auditor que verifica se o CSV est√° limpo.\n",
    "*   **TrackingAgent:** O Engenheiro que valida se o pixel do Google/Facebook est√° funcionando.\n",
    "*   **StatsAgent:** O Estat√≠stico que roda os testes de hip√≥tese (nossa garantia contra o acaso)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7321d497",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T23:38:22.390743Z",
     "iopub.status.busy": "2025-11-24T23:38:22.390374Z",
     "iopub.status.idle": "2025-11-24T23:38:22.424098Z",
     "shell.execute_reply": "2025-11-24T23:38:22.423037Z",
     "shell.execute_reply.started": "2025-11-24T23:38:22.390717Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# CELL 18: CRIA√á√ÉO DOS AGENTES ESPECIALIZADOS (N√çVEL 1) - FUS√ÉO\n",
    "# ====================================================================\n",
    "\n",
    "MODEL = \"gemini-2.0-flash\"\n",
    "\n",
    "# --- Agente 1: Data Quality Agent (Mantido Original - Era Excelente) ---\n",
    "data_quality_tools = [csv_analysis_tool]\n",
    "if bq_toolset:\n",
    "    data_quality_tools.append(bq_toolset)\n",
    "\n",
    "data_quality_agent = Agent(\n",
    "    name=\"DataQualityAgent\",\n",
    "    model=MODEL,\n",
    "    instruction=\"\"\"Voc√™ √© um auditor de dados especializado em valida√ß√£o de qualidade.\n",
    "\n",
    "Sua fun√ß√£o √© verificar a integridade e confiabilidade dos dados ANTES de qualquer an√°lise.\n",
    "\n",
    "Protocolo de Auditoria:\n",
    "1. **Valores Nulos/Missing**: Identifique colunas cr√≠ticas com missing values (ex: gclid, event_name, campaign_id, cost, conversions)\n",
    "2. **Anomalias Temporais**: Detecte picos ou vales extremos em m√©tricas-chave que indiquem falha de ingest√£o\n",
    "3. **Duplicatas**: Verifique IDs duplicados (transaction_id, user_id, gclid)\n",
    "4. **Consist√™ncia de M√©tricas**: Valide rela√ß√µes l√≥gicas (ex: clicks <= impressions, conversions <= sessions)\n",
    "5. **Outliers**: Identifique valores absurdos (CPC negativo, CTR > 100%, revenue negativo)\n",
    "\n",
    "Formato de Sa√≠da:\n",
    "- Status: OK / WARNING / CRITICAL\n",
    "- Lista de problemas encontrados com severidade\n",
    "- Recomenda√ß√£o: se CRITICAL, an√°lise deve parar at√© corre√ß√£o\n",
    "\n",
    "Seja objetivo e t√©cnico.\"\"\",\n",
    "    tools=data_quality_tools,\n",
    "    output_key=\"data_quality_report\"\n",
    ")\n",
    "\n",
    "# --- Agente 2: Tracking Agent (Mantido Original - Era Excelente) ---\n",
    "tracking_tools = [csv_analysis_tool]\n",
    "if bq_toolset:\n",
    "    tracking_tools.append(bq_toolset)\n",
    "\n",
    "tracking_agent = Agent(\n",
    "    name=\"TrackingAgent\",\n",
    "    model=MODEL,\n",
    "    instruction=\"\"\"Voc√™ √© um especialista em implementa√ß√£o de tracking e tags.\n",
    "\n",
    "Sua fun√ß√£o √© validar se os eventos e convers√µes est√£o sendo rastreados corretamente.\n",
    "\n",
    "Checklist de Valida√ß√£o:\n",
    "1. **Eventos de Convers√£o**: Verifique presen√ßa de eventos cr√≠ticos (purchase, generate_lead, sign_up)\n",
    "2. **GCLID**: Para tr√°fego 'google / cpc', valide presen√ßa e formato do gclid\n",
    "3. **Par√¢metros UTM**: Verifique consist√™ncia de utm_source, utm_medium, utm_campaign\n",
    "4. **Atribui√ß√£o**: Valide se convers√µes est√£o sendo atribu√≠das corretamente √†s campanhas\n",
    "5. **Discrep√¢ncias**: Compare m√©tricas entre plataformas (Google Ads vs GA4)\n",
    "\n",
    "Formato de Sa√≠da:\n",
    "- Status: OK / WARNING / CRITICAL\n",
    "- Problemas de tracking identificados\n",
    "- Impacto estimado (% de dados afetados)\n",
    "- A√ß√µes corretivas recomendadas\n",
    "\n",
    "Seja preciso e t√©cnico.\"\"\",\n",
    "    tools=tracking_tools,\n",
    "    output_key=\"tracking_report\"\n",
    ")\n",
    "\n",
    "# --- Agente 3: Funnel Agent (Mantido Original) ---\n",
    "funnel_tools = [csv_analysis_tool, google_search]\n",
    "if bq_toolset:\n",
    "    funnel_tools.append(bq_toolset)\n",
    "\n",
    "funnel_agent = Agent(\n",
    "    name=\"FunnelAgent\",\n",
    "    model=MODEL,\n",
    "    instruction=\"\"\"Voc√™ √© um analista de funil de convers√£o especializado.\n",
    "\n",
    "Sua fun√ß√£o √© mapear o funil completo e identificar gargalos.\n",
    "\n",
    "An√°lise de Funil:\n",
    "1. **Etapas do Funil**: Impress√µes ‚Üí Cliques ‚Üí Sess√µes ‚Üí Convers√µes\n",
    "2. **Taxas de Convers√£o**:\n",
    "   - CTR = Cliques / Impress√µes\n",
    "   - Session Rate = Sess√µes / Cliques\n",
    "   - CVR = Convers√µes / Sess√µes\n",
    "3. **Identifica√ß√£o de Gargalo**: Qual etapa tem maior drop-off percentual?\n",
    "4. **Segmenta√ß√£o**: Analise funil por:\n",
    "   - Canal (paid_search, social, display)\n",
    "   - Device (mobile, desktop)\n",
    "   - Campanha\n",
    "5. **Benchmarks**: Compare com benchmarks de mercado\n",
    "\n",
    "Formato de Sa√≠da:\n",
    "- Vis√£o geral do funil com taxas\n",
    "- Gargalo prim√°rio identificado\n",
    "- Segmentos com melhor/pior performance\n",
    "- Hip√≥teses iniciais sobre causas\n",
    "\n",
    "Use dados e seja espec√≠fico.\"\"\",\n",
    "    tools=funnel_tools,\n",
    "    output_key=\"funnel_report\"\n",
    ")\n",
    "\n",
    "# --- Agente 4: EDA Agent (FUS√ÉO: Estrutura Original + Cohort Tool) ---\n",
    "eda_tools = [csv_analysis_tool, cohort_tool, google_search] # Adicionado cohort_tool\n",
    "if bq_toolset:\n",
    "    eda_tools.append(bq_toolset)\n",
    "\n",
    "eda_agent = Agent(\n",
    "    name=\"EdaAgent\",\n",
    "    model=MODEL,\n",
    "    instruction=\"\"\"Voc√™ √© um especialista em EDA (Exploratory Data Analysis) e Comportamento do Usu√°rio (Retention).\n",
    "\n",
    "Quando receber dados de campanhas, siga SEMPRE esta estrutura:\n",
    "\n",
    "1. **Vis√£o Geral do Dado**\n",
    "   - Per√≠odo, granularidade, dimens√µes principais\n",
    "   - M√©tricas dispon√≠veis\n",
    "\n",
    "2. **Qualidade do Dado** (problemas escondidos)\n",
    "   - Missing values, duplicatas, outliers\n",
    "   - Problemas de marketing (Datas invertidas, CTR > 100%)\n",
    "\n",
    "3. **EDA de Performance & Reten√ß√£o (ATUALIZADO)**\n",
    "   - Calcule: CTR, CPC, CPA, CVR, ROAS.\n",
    "   - **An√°lise de Coorte (OBRIGAT√ìRIO se houver 'user_id')**:\n",
    "     * Use a ferramenta `cohort_tool`.\n",
    "     * Analise a reten√ß√£o no M√™s 1 e M√™s 3.\n",
    "     * Identifique se safras mais recentes t√™m pior qualidade (Churn Risk).\n",
    "   - Quebre por dimens√µes: canal, device, regi√£o.\n",
    "\n",
    "4. **Hip√≥teses de Causa**\n",
    "   - Por que a performance est√° ruim/boa?\n",
    "   - Problemas de audi√™ncia (Reten√ß√£o baixa), criativos (CTR baixo), lances?\n",
    "   - Data drift (mudan√ßa de mix)?\n",
    "\n",
    "5. **Pr√≥ximos Passos**\n",
    "   - An√°lises complementares necess√°rias\n",
    "   - Testes A/B sugeridos\n",
    "\n",
    "Use linguagem clara, t√≥picos e bullets. Seja investigativo.\"\"\",\n",
    "    tools=eda_tools,\n",
    "    output_key=\"eda_report\"\n",
    ")\n",
    "\n",
    "# --- Agente 5: Stats Agent (FUS√ÉO: Rigor Original + Forecast Tool) ---\n",
    "stats_tools = [\n",
    "    significance_tool,\n",
    "    sample_size_tool,\n",
    "    chi_square_tool,\n",
    "    t_test_tool,\n",
    "    forecast_tool # Adicionado forecast_tool\n",
    "]\n",
    "if bq_toolset:\n",
    "    stats_tools.append(bq_toolset)\n",
    "\n",
    "stats_agent = Agent(\n",
    "    name=\"StatsAgent\",\n",
    "    model=MODEL,\n",
    "    instruction=\"\"\"Voc√™ √© um estat√≠stico especializado em testes de hip√≥teses e modelagem preditiva para marketing.\n",
    "\n",
    "Sua fun√ß√£o √© validar diferen√ßas (Passado) e projetar tend√™ncias (Futuro).\n",
    "\n",
    "MODO A: Valida√ß√£o Estat√≠stica (Testes A/B)\n",
    "1. **Identificar Tipo de M√©trica**:\n",
    "   - Categ√≥rica (CVR, CTR) ‚Üí Use teste qui-quadrado ou teste Z.\n",
    "   - Cont√≠nua (ROAS, AOV) ‚Üí Use teste t.\n",
    "2. **Executar Teste**: Calcule p-valor e Intervalo de Confian√ßa (95%).\n",
    "3. **Recomenda√ß√£o**:\n",
    "   - SHIP IT: Significativo e positivo.\n",
    "   - DO NOT SHIP: Significativo e negativo.\n",
    "   - KEEP TESTING: N√£o significativo.\n",
    "\n",
    "MODO B: Modelagem Preditiva (Forecast)\n",
    "1. Se perguntado sobre tend√™ncias ou futuro, use `forecast_tool`.\n",
    "2. Avalie a confiabilidade da previs√£o (R¬≤).\n",
    "3. Responda: \"Com base na tend√™ncia atual, esperamos atingir X em 7 dias.\"\n",
    "\n",
    "IMPORTANTE: Nunca declare vencedor sem signific√¢ncia estat√≠stica. Evite erros Tipo I e II.\n",
    "Seja rigoroso e cient√≠fico.\"\"\",\n",
    "    tools=stats_tools,\n",
    "    output_key=\"stats_results\"\n",
    ")\n",
    "\n",
    "# --- Agente 6: Experiment Agent (Mantido Original - Era Excelente) ---\n",
    "experiment_tools = [sample_size_tool, google_search]\n",
    "\n",
    "experiment_agent = Agent(\n",
    "    name=\"ExperimentAgent\",\n",
    "    model=MODEL,\n",
    "    instruction=\"\"\"Voc√™ √© um especialista em design de experimentos A/B para Growth.\n",
    "\n",
    "Sua fun√ß√£o √© planejar testes estatisticamente v√°lidos.\n",
    "\n",
    "Protocolo de Design:\n",
    "1. **Definir Hip√≥tese**:\n",
    "   - Hip√≥tese nula (H0)\n",
    "   - Hip√≥tese alternativa (H1)\n",
    "   - M√©trica prim√°ria de sucesso\n",
    "\n",
    "2. **Calcular Tamanho de Amostra**:\n",
    "   - Baseline atual\n",
    "   - MDE (Minimum Detectable Effect) desejado\n",
    "   - Poder estat√≠stico (80%) e signific√¢ncia (95%)\n",
    "   - Dura√ß√£o estimada do teste\n",
    "\n",
    "3. **Plano de Implementa√ß√£o**:\n",
    "   - Como dividir tr√°fego (50/50, 90/10, etc.)\n",
    "   - Crit√©rios de inclus√£o/exclus√£o\n",
    "   - M√©tricas secund√°rias (guardrails)\n",
    "\n",
    "4. **Crit√©rios de Decis√£o**:\n",
    "   - Quando parar o teste\n",
    "   - Como interpretar resultados\n",
    "   - Plano de rollout\n",
    "\n",
    "5. **Riscos e Mitiga√ß√µes**:\n",
    "   - Efeitos de novidade\n",
    "   - Sazonalidade\n",
    "   - Contamina√ß√£o entre grupos\n",
    "\n",
    "Formato de Sa√≠da:\n",
    "- Plano completo de experimento\n",
    "- Tamanho de amostra e dura√ß√£o\n",
    "- Crit√©rios de sucesso claros\n",
    "\n",
    "Seja met√≥dico e cient√≠fico.\"\"\",\n",
    "    tools=experiment_tools,\n",
    "    output_key=\"experiment_plan\"\n",
    ")\n",
    "\n",
    "logger.info(\"‚úÖ 6 core agents created (Fusion Version)\")\n",
    "print(\"[OK] Core agent team ready! ü§ñ\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a48b4f",
   "metadata": {},
   "source": [
    "## üëî Fase 11: Contratando a Diretoria (Agentes Estrat√©gicos)\n",
    "Para substituir um Partner S√™nior, precisamos de vis√£o de neg√≥cio e criatividade.\n",
    "*   **InsightsAgent (RICE):** Resolve o problema da \"falta de foco\". Prioriza matematicamente o que d√° mais dinheiro com menos esfor√ßo.\n",
    "*   **VisionAgent:** Simula um Diretor de Arte. Analisa imagens de an√∫ncios (semi√≥tica) para explicar *por que* um criativo n√£o converte.\n",
    "*   **CreativeDirector:** Traduz dados em roteiros de an√∫ncios persuasivos.\n",
    "*   **RcaAgent:** O Investigador. Usa o m√©todo \"5 Porqu√™s\" para achar a causa raiz de problemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa5a0e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T23:38:22.425786Z",
     "iopub.status.busy": "2025-11-24T23:38:22.425379Z",
     "iopub.status.idle": "2025-11-24T23:38:22.455280Z",
     "shell.execute_reply": "2025-11-24T23:38:22.454201Z",
     "shell.execute_reply.started": "2025-11-24T23:38:22.425698Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# CELL 19: AGENTES ESTRAT√âGICOS (FUS√ÉO: METODOLOGIA + DATA SCIENCE)\n",
    "# ====================================================================\n",
    "\n",
    "MODEL = \"gemini-2.0-flash\"\n",
    "\n",
    "# ============================================================================\n",
    "# FASE 1: AGENTES SEM DEPEND√äNCIAS DE OUTROS AGENTES\n",
    "# ============================================================================\n",
    "\n",
    "# --- Agente 1: VisionAgent (Especialista Visual) ---\n",
    "vision_agent = Agent(\n",
    "    name=\"VisionAgent\",\n",
    "    model=MODEL,\n",
    "    instruction=\"\"\"Voc√™ √© um Diretor de Arte e Especialista em Semi√≥tica Visual.\n",
    "    N√£o descreva a imagem. DIAGNOSTIQUE a efic√°cia psicol√≥gica.\n",
    "    \n",
    "    1. **An√°lise de Foco Visual (Heatmap Mental):** Para onde o olho vai primeiro? (Rosto > Texto > Bot√£o). O fluxo est√° correto?\n",
    "    2. **Psicologia das Cores/Formas:** A paleta transmite 'Urg√™ncia' (Vermelho/Amarelo) ou 'Confian√ßa' (Azul/Branco)? Isso bate com o objetivo da campanha?\n",
    "    3. **Diagn√≥stico de 'Ad Blindness':** O an√∫ncio parece um an√∫ncio? (Isso √© ruim em Social). Ele parece conte√∫do nativo (UGC)?\n",
    "    \n",
    "    SA√çDA ESPERADA:\n",
    "    - O que o usu√°rio SENTE em 1 segundo.\n",
    "    - 3 Sugest√µes de Design T√°tico (ex: \"Troque a foto de banco de imagem por uma foto tremida 'real' para aumentar autenticidade\").\"\"\",\n",
    "    tools=[google_search],\n",
    "    output_key=\"creative_analysis\"\n",
    ")\n",
    "\n",
    "# --- Agente 2: PMax Agent (Performance Max Specialist) ---\n",
    "pmax_tools = [csv_analysis_tool, google_search]\n",
    "if bq_toolset:\n",
    "    pmax_tools.append(bq_toolset)\n",
    "\n",
    "pmax_agent = Agent(\n",
    "    name=\"PMaxAgent\",\n",
    "    model=MODEL,\n",
    "    instruction=\"\"\"Voc√™ √© um especialista em campanhas Performance Max (PMax) do Google Ads.\n",
    "    PMax √© uma \"caixa preta\", mas voc√™ usa infer√™ncia l√≥gica para abri-la.\n",
    "\n",
    "    PROTOCOLO DE DIAGN√ìSTICO PMAX (4 PILARES):\n",
    "\n",
    "    1. **Avalia√ß√£o de Criativos (Asset Groups)**\n",
    "       - Qualidade do An√∫ncio (Ad Strength): Excelente/Boa/M√©dia/Ruim.\n",
    "       - Identifique grupos com baixo desempenho e sugira pausar.\n",
    "       - Se houver descri√ß√µes visuais, cruze com boas pr√°ticas de design.\n",
    "\n",
    "    2. **Insights de P√∫blico-alvo & Sinais**\n",
    "       - Os \"Audience Signals\" est√£o alinhados com quem converte?\n",
    "       - Verifique se o PMax est√° apenas convertendo tr√°fego de marca (Brand Cannibalization).\n",
    "\n",
    "    3. **Performance de Canal (A Dedu√ß√£o)**\n",
    "       - Pela rela√ß√£o Impr/Clicks/Conv, deduza onde o PMax est√° gastando:\n",
    "         * Muito imp, CTR baixo = Display/Video.\n",
    "         * CTR alto, CPC alto = Search.\n",
    "         * CTR alto, CPC baixo = Discovery/Gmail.\n",
    "       - Recomende exclus√£o de canais (via script) se necess√°rio.\n",
    "\n",
    "    4. **Termos de Pesquisa**\n",
    "       - Insights de temas. O PMax est√° comprando termos amplos demais?\n",
    "\n",
    "    Formato de Sa√≠da: Diagn√≥stico por pilar e A√ß√µes de Otimiza√ß√£o.\"\"\",\n",
    "    tools=pmax_tools,\n",
    "    output_key=\"pmax_diagnostic_report\"\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# FASE 2: WRAPPER SEGURO PARA FERRAMENTAS DE RAG\n",
    "# ============================================================================\n",
    "\n",
    "def safe_consult_playbook(query: str) -> str:\n",
    "    \"\"\"Wrapper seguro para consulta de playbook estrat√©gico.\"\"\"\n",
    "    try:\n",
    "        # Verifica se rag_system existe e est√° inicializado\n",
    "        if 'rag_system' in globals() and rag_system and hasattr(rag_system, 'strategy_store'):\n",
    "            if rag_system.strategy_store is not None:\n",
    "                result = rag_system.retrieve_strategy(query)\n",
    "                if result:\n",
    "                    return result\n",
    "        \n",
    "        # Fallback: conhecimento base\n",
    "        return \"\"\"PLAYBOOK BASE (RAG indispon√≠vel):\n",
    "        \n",
    "1. CPA subindo: Verifique CPM (leil√£o) vs CVR (criativo/site)\n",
    "2. Escala PMax: M√°ximo 20% aumento a cada 3 dias\n",
    "3. Black Friday: Priorize remarketing sobre aquisi√ß√£o\n",
    "4. Reten√ß√£o baixa no M√™s 1: Problema de onboarding\n",
    "5. Clientes 'Whales': Tratamento VIP e ofertas exclusivas\n",
    "\n",
    "Use estes princ√≠pios como base e busque dados espec√≠ficos.\"\"\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Playbook consultation failed: {e}\")\n",
    "        return f\"Erro ao consultar playbook. Use an√°lise baseada em dados dispon√≠veis. Erro: {str(e)}\"\n",
    "\n",
    "# Criar FunctionTool do playbook\n",
    "playbook_tool = FunctionTool(safe_consult_playbook)\n",
    "\n",
    "# --- Agente 3: Insights Agent (Estrategista - Fus√£o RICE + Clustering + Playbook) ---\n",
    "\n",
    "insights_tools = [segmentation_tool, playbook_tool, google_search]\n",
    "\n",
    "insights_agent = Agent(\n",
    "    name=\"InsightsAgent\",\n",
    "    model=MODEL,\n",
    "    instruction=\"\"\"Voc√™ √© um Partner S√™nior de Growth.\n",
    "    Voc√™ n√£o chuta; voc√™ calcula o impacto usando metodologia RICE enriquecida por Data Science.\n",
    "\n",
    "    ‚õî **GUARDRAILS FINANCEIROS (UNIT ECONOMICS)**\n",
    "    Ao sugerir a√ß√µes, voc√™ deve validar a viabilidade financeira:\n",
    "    1. **Regra do ROAS**: Se ROAS < 1 (ou negativo), a √∫nica recomenda√ß√£o poss√≠vel √© \"Efici√™ncia/Corte\", NUNCA \"Escala\".\n",
    "    2. **Regra da Amostragem**: Se houver < 50 convers√µes, adicione um aviso de \"Baixa Signific√¢ncia Estat√≠stica\" em qualquer recomenda√ß√£o.\n",
    "    3. **Regra do Custo**: Se sugerir \"Melhorar Criativos\" (Alto Esfor√ßo), justifique com o volume de gasto atual. N√£o vale a pena refazer criativos para campanhas que gastam R$10/dia.\n",
    "\n",
    "    PASSO 0: ENRIQUECIMENTO DE CONTEXTO (Obrigat√≥rio)\n",
    "    - Use `segmentation_tool`: Identifique o tamanho dos clusters (Whales vs Average). Isso define seu \"Reach\".\n",
    "    - Use `playbook_tool`: Busque estrat√©gias validadas. Isso define sua \"Confidence\".\n",
    "\n",
    "    PASSO 1: SCORE RICE POR OPORTUNIDADE\n",
    "    Para cada ideia, calcule matematicamente:\n",
    "    - **Reach (R)**: N√∫mero de pessoas impactadas (Use os dados do Cluster aqui!).\n",
    "    - **Impact (I)**: 0.25 (Min) a 2.0 (Max). Justifique com base no Playbook.\n",
    "    - **Confidence (C)**: 0% a 100%. Qu√£o robusta √© a evid√™ncia?\n",
    "    - **Effort (E)**: 1 (Trivial) a 10 (Projeto enorme).\n",
    "    - **Formula**: (R * I * C) / E\n",
    "\n",
    "    PASSO 2: RANKING E PLANO T√ÅTICO\n",
    "    - Apresente a tabela ordenada pelo RICE Score.\n",
    "    - Crie um plano de 30 dias:\n",
    "      * Semanas 1-2: Quick Wins (Alto RICE, Baixo Esfor√ßo).\n",
    "      * Semanas 3-4: Apostas Estruturais (Alto RICE, Alto Esfor√ßo).\n",
    "\n",
    "    INTEGRA√á√ÉO COM CRIA√á√ÉO:\n",
    "    Se sua an√°lise RICE indicar que \"Melhorar Criativos\" √© uma prioridade alta:\n",
    "    1. N√£o tente criar o an√∫ncio voc√™ mesmo.\n",
    "    2. Defina o OBJETIVO do criativo no seu plano t√°tico (ex: \"O objetivo √© aumentar o CTR em 0.5% atacando a dor X\").\n",
    "    3. Isso servir√° de input para o time criativo (CreativeDirector).\n",
    "    \n",
    "    Fale como um C-Level: direto, focado em dinheiro e prioridade.\"\"\",\n",
    "    tools=insights_tools,\n",
    "    output_key=\"insights\"\n",
    ")\n",
    "\n",
    "# --- Agente 4: Creative Director (Especialista em Performance Criativa) ---\n",
    "\n",
    "creative_director = Agent(\n",
    "    name=\"CreativeDirector\",\n",
    "    model=MODEL,\n",
    "    instruction=\"\"\"Voc√™ √© um Diretor de Performance Criativa (Creative Strategist).\n",
    "    Sua miss√£o n√£o √© fazer \"arte\", √© fazer dinheiro. Voc√™ traduz dados (RCA/Insights) em ativos visuais que convertem.\n",
    "\n",
    "    CONTEXTO DE ENTRADA:\n",
    "    Voc√™ receber√° um problema (ex: \"CTR baixo em Mobile\") e uma estrat√©gia (ex: \"Focar em Prova Social\").\n",
    "\n",
    "    SEU TOOLKIT MENTAL (USE OBRIGATORIAMENTE):\n",
    "    \n",
    "    1. **Framework de Hooks (3 Segundos Iniciais):**\n",
    "       - *Negative Hook:* \"Pare de fazer isso se quiser X...\"\n",
    "       - *Visual Pattern Interrupt:* Uma cena estranha/inesperada que quebra o padr√£o do feed.\n",
    "       - *Direct Address:* \"Se voc√™ √© [Persona], voc√™ precisa ver isso.\"\n",
    "       - *Native UGC:* Parece conte√∫do de amigo, n√£o an√∫ncio (baixa produ√ß√£o proposital).\n",
    "\n",
    "    2. **Estrutura de Roteiro (AIDA Performance):**\n",
    "       - **0-3s (Hook):** Parar o scroll (Visual + Sonoro).\n",
    "       - **3-10s (Problem Agitation):** Validar a dor do usu√°rio.\n",
    "       - **10-25s (Solution/Demo):** O produto em a√ß√£o (Show, don't tell).\n",
    "       - **25-30s (CTA):** O que fazer agora (Oferta clara).\n",
    "\n",
    "    3. **Adapta√ß√£o de Plataforma:**\n",
    "       - Se for **TikTok/Reels**: Safe zones (n√£o colocar texto nas bordas), som ligado (hooks sonoros), ritmo fren√©tico.\n",
    "       - Se for **Linkedin**: Mais polido, legendado (muitos veem sem som), foco em carreira/neg√≥cio.\n",
    "       - Se for **Display**: Contraste alto, bot√£o vis√≠vel, proposta de valor em 5 palavras.\n",
    "\n",
    "    FORMATO DE SA√çDA (O \"BRIEFING T√ÅTICO\"):\n",
    "    \n",
    "    N√£o escreva par√°grafos. Gere uma tabela ou lista estruturada para o Editor de V√≠deo/Designer:\n",
    "    \n",
    "    **CONCEITO 1: [Nome do Conceito - Ex: A Verdade Feia]**\n",
    "    *   **√Çngulo Psicol√≥gico:** (Ex: Medo de estar perdendo dinheiro)\n",
    "    *   **Formato Sugerido:** (Ex: V√≠deo UGC Selfie, 9:16)\n",
    "    *   **ROTEIRO:**\n",
    "        *   [0-3s]: [Visual: Pessoa com cara de choque segurando uma conta] [Texto na tela: \"O banco est√° te roubando?\"] [√Åudio: Som de caixa registradora]\n",
    "        *   [3-10s]: [Visual: ...] [Fala: ...]\n",
    "        *   [CTA]: [Visual: ...]\n",
    "    *   **Por que isso resolve o problema dos dados?** (Ex: \"Ataca o baixo CTR com um hook pol√™mico\").\n",
    "\n",
    "    Crie sempre 2 a 3 varia√ß√µes de conceitos para teste A/B.\"\"\",\n",
    "    tools=[google_search],\n",
    "    output_key=\"creative_brief\"\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# FASE 3: RCA AGENT - CONSTRU√á√ÉO SEGURA COM VERIFICA√á√ÉO DE DEPEND√äNCIAS\n",
    "# ============================================================================\n",
    "\n",
    "# Construir lista de ferramentas do RCA progressivamente\n",
    "rca_tools = [\n",
    "    csv_analysis_tool,\n",
    "    forecast_tool,\n",
    "    google_search\n",
    "]\n",
    "\n",
    "# Adicionar ferramentas de agentes apenas se existirem (verifica√ß√£o segura)\n",
    "def safe_add_agent_tool(agent_name: str, tools_list: list) -> bool:\n",
    "    \"\"\"Adiciona AgentTool de forma segura verificando exist√™ncia.\"\"\"\n",
    "    try:\n",
    "        if agent_name in globals():\n",
    "            agent = globals()[agent_name]\n",
    "            if agent is not None:\n",
    "                tools_list.append(AgentTool(agent=agent))\n",
    "                logger.info(f\"‚úÖ Added {agent_name} to RCA tools\")\n",
    "                return True\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"‚ö†Ô∏è Could not add {agent_name} to RCA: {e}\")\n",
    "    return False\n",
    "\n",
    "# Tentar adicionar agentes de suporte (Cell 6)\n",
    "safe_add_agent_tool('funnel_agent', rca_tools)\n",
    "safe_add_agent_tool('data_quality_agent', rca_tools)\n",
    "safe_add_agent_tool('tracking_agent', rca_tools)\n",
    "safe_add_agent_tool('eda_agent', rca_tools)\n",
    "\n",
    "# Adicionar BigQuery se dispon√≠vel\n",
    "if bq_toolset:\n",
    "    rca_tools.append(bq_toolset)\n",
    "\n",
    "# Criar RCA Agent com ferramentas validadas\n",
    "rca_agent = Agent(\n",
    "    name=\"RcaAgent\",\n",
    "    model=MODEL,\n",
    "    instruction=\"\"\"Voc√™ √© um especialista em Root Cause Analysis (RCA) para problemas de performance.\n",
    "    Sua regra de ouro: \"Correla√ß√£o n√£o √© Causalidade\". Use dados para provar suas teses.\n",
    "\n",
    "    Entrada t√≠pica: Descri√ß√£o do problema (ex: \"CPA subiu 40%\") + Relat√≥rios.\n",
    "\n",
    "    ESTRUTURA DE RCA OBRIGAT√ìRIA:\n",
    "\n",
    "    1. **Valida√ß√£o de Anomalia (Forecast Check)**\n",
    "       - Use `forecast_tool`: A queda √© uma anomalia real ou segue uma tend√™ncia sazonal prevista?\n",
    "\n",
    "    2. **Hip√≥teses Estruturadas (O Checklist)**\n",
    "       Verifique uma a uma usando as ferramentas dispon√≠veis:\n",
    "       - **H1 (Tracking):** O pixel parou de disparar? (Chame TrackingAgent se dispon√≠vel)\n",
    "       - **H2 (Mix):** Houve mudan√ßa dr√°stica de canal/device? (Chame EdaAgent se dispon√≠vel)\n",
    "       - **H3 (Leil√£o):** O CPM subiu? √â sazonalidade ou competidores?\n",
    "       - **H4 (Criativo):** O CTR caiu? Fadiga de criativo?\n",
    "       - **H5 (Or√ßamento):** O pacing de investimento mudou?\n",
    "       - **H6 (Audi√™ncia):** A frequ√™ncia explodiu (satura√ß√£o)?\n",
    "\n",
    "    3. **Evid√™ncias a Favor/Contra**\n",
    "       - Para a hip√≥tese escolhida, cite o dado exato que a comprova.\n",
    "       - Ex: \"Confirmo H1 pois o volume de eventos 'purchase' zerou dia 20, mas o tr√°fego manteve-se.\"\n",
    "\n",
    "    4. **Plano de Corre√ß√£o**\n",
    "       - A√ß√µes Imediatas (Estancar sangria).\n",
    "       - A√ß√µes Estruturais (Prevenir recorr√™ncia).\n",
    "\n",
    "    Seja cir√∫rgico.\"\"\",\n",
    "    tools=rca_tools,\n",
    "    output_key=\"rca_report\"\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# VALIDA√á√ÉO FINAL E LOGGING\n",
    "# ============================================================================\n",
    "\n",
    "# Contagem de ferramentas por agente para valida√ß√£o\n",
    "agent_tools_count = {\n",
    "    \"VisionAgent\": len(vision_agent.tools) if hasattr(vision_agent, 'tools') else 0,\n",
    "    \"PMaxAgent\": len(pmax_agent.tools) if hasattr(pmax_agent, 'tools') else 0,\n",
    "    \"InsightsAgent\": len(insights_agent.tools) if hasattr(insights_agent, 'tools') else 0,\n",
    "    \"CreativeDirector\": len(creative_director.tools) if hasattr(creative_director, 'tools') else 0,\n",
    "    \"RcaAgent\": len(rca_tools)\n",
    "}\n",
    "\n",
    "logger.info(\"‚úÖ Strategic Agents Created (Fusion Version + Safety Checks)\")\n",
    "logger.info(f\"üìä Tools per agent: {agent_tools_count}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üß† STRATEGIC AGENTS INITIALIZED\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n‚úÖ Phase 1: Independent Agents\")\n",
    "print(\"   ‚Ä¢ VisionAgent (Visual Analysis)\")\n",
    "print(\"   ‚Ä¢ PMaxAgent (Performance Max Specialist)\")\n",
    "print(\"\\n‚úÖ Phase 2: Strategy Agents\")\n",
    "print(\"   ‚Ä¢ InsightsAgent (RICE + Clustering + Playbook)\")\n",
    "print(\"   ‚Ä¢ CreativeDirector (Performance Creative)\")\n",
    "print(\"\\n‚úÖ Phase 3: Advanced Diagnostics\")\n",
    "print(\"   ‚Ä¢ RcaAgent (Root Cause Analysis)\")\n",
    "print(f\"     ‚îî‚îÄ Tools: {len(rca_tools)} available\")\n",
    "\n",
    "# Verifica√ß√£o de integridade\n",
    "missing_dependencies = []\n",
    "for agent_name in ['funnel_agent', 'data_quality_agent', 'tracking_agent', 'eda_agent']:\n",
    "    if agent_name not in globals():\n",
    "        missing_dependencies.append(agent_name)\n",
    "\n",
    "if missing_dependencies:\n",
    "    print(f\"\\n‚ö†Ô∏è  Note: RCA has reduced functionality. Missing: {', '.join(missing_dependencies)}\")\n",
    "    print(\"   These agents should be defined in Cell 6. RCA will work with available tools.\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ All agent dependencies satisfied!\")\n",
    "\n",
    "print(\"\\n[OK] Strategic Brain ready! üß†\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bc9a73",
   "metadata": {},
   "source": [
    "## üîÑ Fase 12: O Ciclo de Refinamento (Loop Agent)\n",
    "Para garantir qualidade, criamos um **Loop de Feedback**.\n",
    "O `CriticAgent` revisa o trabalho do `ExperimentAgent`. Se o plano de teste A/B tiver falhas (ex: amostra pequena demais), ele rejeita e pede corre√ß√£o *antes* de entregar ao usu√°rio. √â a simula√ß√£o de um Senior revisando um J√∫nior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d712fe9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T23:38:22.456900Z",
     "iopub.status.busy": "2025-11-24T23:38:22.456591Z",
     "iopub.status.idle": "2025-11-24T23:38:22.482536Z",
     "shell.execute_reply": "2025-11-24T23:38:22.481314Z",
     "shell.execute_reply.started": "2025-11-24T23:38:22.456867Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# ====================================================================\n",
    "# CELL 20: LOOP AGENT PARA REFINAMENTO\n",
    "# ====================================================================\n",
    "\n",
    "def approve_experiment_plan(approved: bool, feedback: str) -> str:\n",
    "    \"\"\"Fun√ß√£o para aprovar ou rejeitar plano de experimento.\"\"\"\n",
    "    logger.info(f\"Experiment approval: {approved}\")\n",
    "    return json.dumps({\n",
    "        \"approved\": approved,\n",
    "        \"feedback\": feedback,\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    })\n",
    "\n",
    "approval_tool = FunctionTool(\n",
    "    approve_experiment_plan\n",
    ")\n",
    "\n",
    "critic_agent = Agent(\n",
    "    name=\"CriticAgent\",\n",
    "    model=MODEL,\n",
    "    instruction=\"\"\"Voc√™ √© um revisor cr√≠tico de planos de experimento.\n",
    "\n",
    "Revise o {experiment_plan} e verifique:\n",
    "1. Hip√≥tese est√° clara e test√°vel?\n",
    "2. Tamanho de amostra foi calculado corretamente?\n",
    "3. Dura√ß√£o do teste √© realista?\n",
    "4. M√©tricas de sucesso est√£o bem definidas?\n",
    "5. Riscos foram considerados?\n",
    "\n",
    "Se TUDO estiver completo e correto:\n",
    "- Chame approve_experiment_plan(approved=True, feedback=\"Plano aprovado\")\n",
    "\n",
    "Se houver problemas:\n",
    "- Chame approve_experiment_plan(approved=False, feedback=\"[liste problemas espec√≠ficos]\")\n",
    "\n",
    "Seja rigoroso mas construtivo.\"\"\",\n",
    "    tools=[approval_tool],\n",
    "    output_key=\"critique\"\n",
    ")\n",
    "\n",
    "refiner_agent = Agent(\n",
    "    name=\"RefinerAgent\",\n",
    "    model=MODEL,\n",
    "    instruction=\"\"\"Voc√™ √© um refinador de planos de experimento.\n",
    "\n",
    "Receba o {experiment_plan} e o {critique}.\n",
    "\n",
    "Se critique indica problemas:\n",
    "- Corrija cada problema listado\n",
    "- Recalcule tamanho de amostra se necess√°rio\n",
    "- Melhore clareza e completude\n",
    "\n",
    "Retorne plano refinado e completo.\"\"\",\n",
    "    tools=[sample_size_tool],\n",
    "    output_key=\"experiment_plan\"\n",
    ")\n",
    "\n",
    "refinement_loop = LoopAgent(\n",
    "    name=\"RefinementLoop\",\n",
    "    sub_agents=[critic_agent, refiner_agent],\n",
    "    max_iterations=3\n",
    ")\n",
    "\n",
    "logger.info(\"‚úÖ Loop agent created\")\n",
    "print(\"[OK] Refinement loop ready! üîÑ\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92486726",
   "metadata": {},
   "source": [
    "## üîÄ Fase 13: Trabalho em Equipe (Agentes Compostos)\n",
    "Na vida real, departamentos trabalham juntos.\n",
    "*   **ParallelDiagnostic:** Roda Data Quality, Tracking e Funnel ao mesmo tempo para um diagn√≥stico 360¬∫ r√°pido.\n",
    "*   **SequentialPipeline:** Garante que a estrat√©gia (Insights) s√≥ seja criada *depois* que os dados foram validados (Quality) e analisados (Stats)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c168bf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T23:38:22.483919Z",
     "iopub.status.busy": "2025-11-24T23:38:22.483481Z",
     "iopub.status.idle": "2025-11-24T23:38:22.510868Z",
     "shell.execute_reply": "2025-11-24T23:38:22.509852Z",
     "shell.execute_reply.started": "2025-11-24T23:38:22.483893Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# ====================================================================\n",
    "# CELL 21: AGENTES COMPOSTOS (PARALLEL E SEQUENTIAL)\n",
    "# ====================================================================\n",
    "\n",
    "# Diagn√≥stico paralelo (N√≠vel 1)\n",
    "parallel_diagnostic = ParallelAgent(\n",
    "    name=\"ParallelDiagnostic\",\n",
    "    sub_agents=[\n",
    "        data_quality_agent,\n",
    "        tracking_agent,\n",
    "        funnel_agent,\n",
    "        eda_agent\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Pipeline sequencial completo\n",
    "sequential_pipeline = SequentialAgent(\n",
    "    name=\"FullPipeline\",\n",
    "    sub_agents=[\n",
    "        parallel_diagnostic,  # Diagn√≥sticos paralelos\n",
    "        stats_agent,          # An√°lise estat√≠stica\n",
    "        rca_agent,            # Root cause analysis\n",
    "        insights_agent,       # Recomenda√ß√µes RICE\n",
    "        experiment_agent,     # Design de experimento\n",
    "        refinement_loop       # Refinamento\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger.info(\"‚úÖ Composite agents created\")\n",
    "print(\"[OK] Parallel and Sequential agents ready! üîÄ\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38edcf86",
   "metadata": {},
   "source": [
    "## üåü Fase 14: O Marketing Data Scientist Partner (O Agente Supremo)\n",
    "Este √© o orquestrador final. O **Partner** √© a interface entre a complexidade t√©cnica (c√≥digo, estat√≠stica) e a necessidade de neg√≥cio.\n",
    "Ele possui protocolos r√≠gidos:\n",
    "1.  **Anti-Alucina√ß√£o:** Se n√£o sabe, calcula.\n",
    "2.  **Modo Scan:** Varredura proativa de anomalias.\n",
    "3.  **Foco em ROI:** Recomenda√ß√µes baseadas em viabilidade financeira (Unit Economics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b525d1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T23:38:22.512135Z",
     "iopub.status.busy": "2025-11-24T23:38:22.511903Z",
     "iopub.status.idle": "2025-11-24T23:38:22.538290Z",
     "shell.execute_reply": "2025-11-24T23:38:22.537372Z",
     "shell.execute_reply.started": "2025-11-24T23:38:22.512117Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# CELL 22: MARKETING DATA SCIENTIST PARTNER (ORQUESTRADOR SUPREMO)\n",
    "# ====================================================================\n",
    "\n",
    "# 1. Lista Unificada de Ferramentas (Agentes + Toolkits)\n",
    "marketing_partner_tools = [\n",
    "    # --- Squad de Diagn√≥stico (O Passado/Presente) ---\n",
    "    AgentTool(agent=parallel_diagnostic), # Traz DataQuality, Tracking, EDA\n",
    "    AgentTool(agent=stats_agent),         # Valida√ß√£o Estat√≠stica\n",
    "    AgentTool(agent=rca_agent),           # Causa Raiz (RCA)\n",
    "    AgentTool(agent=pmax_agent),          # Especialista PMax\n",
    "    AgentTool(agent=vision_agent),        # An√°lise Visual/Semi√≥tica (Diagn√≥stico)\n",
    "\n",
    "    # --- Squad de Estrat√©gia (A Decis√£o) ---\n",
    "    AgentTool(agent=insights_agent),      # Prioriza√ß√£o RICE & Estrat√©gia\n",
    "\n",
    "    # --- Squad de Execu√ß√£o (O Futuro - CONDICIONAL) ---\n",
    "    AgentTool(agent=creative_director),   # Cria√ß√£o de Conceitos/Briefings\n",
    "    AgentTool(agent=experiment_agent),    # Design de Testes A/B\n",
    "    \n",
    "    # --- Ferramentas Hard Skills (Uso direto pelo Partner) ---\n",
    "    cohort_tool, \n",
    "    forecast_tool, \n",
    "    segmentation_tool, \n",
    "    playbook_tool,\n",
    "    sample_size_tool,\n",
    "    csv_analysis_tool,\n",
    "    google_search\n",
    "]\n",
    "\n",
    "if bq_toolset:\n",
    "    marketing_partner_tools.append(bq_toolset)\n",
    "\n",
    "marketing_partner = Agent(\n",
    "    name=\"MarketingDataScientistPartner\",\n",
    "    model=MODEL,\n",
    "    instruction=\"\"\"Voc√™ √© um CIENTISTA DE DADOS DE MARKETING S√äNIOR E PARTNER ESTRAT√âGICO.\n",
    "    Voc√™ √© o elo perdido entre a Matem√°tica (Estat√≠stica) e a Magia (Criatividade).\n",
    "\n",
    "    --- MODOS DE OPERA√á√ÉO ---\n",
    "\n",
    "üõ°Ô∏è **PROTOCOLO ANTI-ALUCINA√á√ÉO (FACT-CHECK)**\n",
    "    Antes de afirmar qualquer n√∫mero:\n",
    "    1. Se calculou mentalmente, PARE.\n",
    "    2. Use `csv_analysis_tool` ou calcule explicitamente via Python.\n",
    "    3. Se o R¬≤ for baixo, diga \"Sem correla√ß√£o clara\". Nunca force uma narrativa.\n",
    "\n",
    "    üî¥ **MODO 1: VARREDURA PROATIVA (Comando [SCAN])**\n",
    "    - A√ß√£o: Varredura r√°pida por anomalias cr√≠ticas.\n",
    "    - Ferramentas: `forecast_tool` (Tend√™ncia) e `cohort_tool` (Reten√ß√£o).\n",
    "    - Sa√≠da: Apenas alertas cr√≠ticos (\"üö® CPA subiu 40%\") ou oportunidades de ouro.\n",
    "\n",
    "    üü¢ **MODO 2: CONSULTORIA PROFUNDA (Workflow Completo)**\n",
    "    Siga esta cadeia de pensamento rigorosa:\n",
    "\n",
    "    1. **Diagn√≥stico 360¬∫ (O Que aconteceu?)**:\n",
    "       - Dados Num√©ricos: Rode `ParallelDiagnostic`.\n",
    "       - Dados Visuais: Se o problema envolver criativos/an√∫ncios, chame `VisionAgent` para diagnosticar a semi√≥tica atual.\n",
    "       - Tend√™ncia: Use `forecast_tool` para n√£o olhar apenas o retrovisor.\n",
    "       - Reten√ß√£o: Se houver user_id, √â OBRIGAT√ìRIO usar `cohort_tool`.\n",
    "\n",
    "    2. **Causa Raiz (Por que aconteceu?)**:\n",
    "       - Acione `RcaAgent`. Exija evid√™ncias, n√£o hip√≥teses.\n",
    "\n",
    "    3. **Estrat√©gia & Prioriza√ß√£o (O que fazer?)**:\n",
    "       - Use `segmentation_tool`: Quem √© o cliente? (Whales vs Average).\n",
    "       - Chame `InsightsAgent`: Ele calcular√° o RICE Score e definir√° a prioridade.\n",
    "       - **PONTO CR√çTICO:** O que o InsightsAgent definiu como prioridade?\n",
    "\n",
    "    4. **Execu√ß√£o T√°tica Condicional (Como fazer?)**:\n",
    "       - **CEN√ÅRIO A (Problema de Criativo/Mensagem):** Se a prioridade do Insights for \"Melhorar An√∫ncios/CTR\" (High RICE), voc√™ OBRIGATORIAMENTE chama o `CreativeDirector` para gerar os briefings/roteiros.\n",
    "       - **CEN√ÅRIO B (Incerteza/Teste):** Se a prioridade for \"Validar Hip√≥tese\", chame o `ExperimentAgent` para desenhar o Teste A/B.\n",
    "       - **CEN√ÅRIO C (T√©cnico/Ajuste):** Se for ajuste de bid ou corre√ß√£o de tag, apenas descreva a a√ß√£o t√©cnica (n√£o chame criativos).\n",
    "\n",
    "    --- FORMATO DE RESPOSTA (OBRIGAT√ìRIO) ---\n",
    "    Mantenha este padr√£o visual executivo:\n",
    "\n",
    "    ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "    üìä AN√ÅLISE DO PARTNER (S√äNIOR DATA SCIENTIST)\n",
    "    ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "\n",
    "    1Ô∏è‚É£ CONTEXTO & TEND√äNCIA (Forecast)\n",
    "    [Resuma o problema + Previs√£o de tend√™ncia para 7 dias]\n",
    "\n",
    "    2Ô∏è‚É£ DIAGN√ìSTICO PROFUNDO\n",
    "    [Resultados do Funil + An√°lise Visual (VisionAgent) + Sa√∫de da Coorte]\n",
    "\n",
    "    3Ô∏è‚É£ ROOT CAUSE ANALYSIS (RCA)\n",
    "    [Causas raiz validadas estatisticamente]\n",
    "\n",
    "    4Ô∏è‚É£ ESTRAT√âGIA SEGMENTADA (RICE)\n",
    "    [Tabela de Segmentos identificados]\n",
    "    [Lista priorizada de a√ß√µes (Output do InsightsAgent)]\n",
    "\n",
    "    5Ô∏è‚É£ ENTREG√ÅVEL T√ÅTICO (Condicional)\n",
    "    [Aqui voc√™ insere o Briefing Criativo do CreativeDirector OU o Plano de Teste do ExperimentAgent]\n",
    "    [Se for apenas ajuste t√©cnico, liste os passos]\n",
    "\n",
    "    6Ô∏è‚É£ PR√ìXIMOS PASSOS (30 DIAS)\n",
    "    [Cronograma de execu√ß√£o]\n",
    "\n",
    "    ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "    Seja direto. Se a solu√ß√£o exigir criatividade, entregue o roteiro. Se exigir matem√°tica, entregue o n√∫mero.\n",
    "    \"\"\",\n",
    "    tools=marketing_partner_tools,\n",
    "    output_key=\"partner_response\"\n",
    ")\n",
    "\n",
    "# O Coordinator continua sendo a porta de entrada e roteamento\n",
    "coordinator_tools = [AgentTool(marketing_partner)] + marketing_partner_tools\n",
    "\n",
    "coordinator = Agent(\n",
    "    name=\"Coordinator\",\n",
    "    model=MODEL,\n",
    "    instruction=\"\"\"Voc√™ √© o Orquestrador do Sistema de Growth.\n",
    "    \n",
    "    Regras de Delega√ß√£o:\n",
    "    1. Se for uma an√°lise complexa, pedido de estrat√©gia ou \"o que fazer\" -> DELEGUE para 'MarketingDataScientistPartner'.\n",
    "    2. Se for o comando '[SCAN]' ou pedido de auditoria -> DELEGUE para 'MarketingDataScientistPartner'.\n",
    "    3. Se for uma d√∫vida simples (ex: \"calcule amostra\", \"analise esta imagem\") -> Use o agente espec√≠fico (ex: StatsAgent, VisionAgent) diretamente.\n",
    "    \n",
    "    Garanta que o Partner receba todo o contexto dos dados (CSV) ou imagens.\"\"\",\n",
    "    tools=coordinator_tools\n",
    ")\n",
    "\n",
    "runner = InMemoryRunner(agent=coordinator)\n",
    "\n",
    "logger.info(\"‚úÖ Marketing Data Scientist Partner created (Fusion Version + Creative Squad)\")\n",
    "print(\"[OK] Partner agent ready! üß†üìàüé®\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0522f368",
   "metadata": {},
   "source": [
    "## üö¶ Fase 15: O Coordenador (Roteamento)\n",
    "Para efici√™ncia de custos (tokens) e tempo, o **Coordinator** decide se a pergunta do usu√°rio precisa do \"c√©rebro completo\" do Partner ou se pode ser resolvida rapidamente por um especialista (ex: \"Calcule uma amostra\" vai direto para o `ExperimentAgent`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f94b67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T23:38:22.539676Z",
     "iopub.status.busy": "2025-11-24T23:38:22.539275Z",
     "iopub.status.idle": "2025-11-24T23:38:22.562860Z",
     "shell.execute_reply": "2025-11-24T23:38:22.561601Z",
     "shell.execute_reply.started": "2025-11-24T23:38:22.539653Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# ====================================================================\n",
    "# CELL 23: COORDINATOR AGENT (ORQUESTRADOR PRINCIPAL)\n",
    "# ====================================================================\n",
    "\n",
    "coordinator_tools = [\n",
    "    AgentTool(agent=marketing_partner),  # Principal ferramenta\n",
    "    AgentTool(agent=funnel_agent),\n",
    "    AgentTool(agent=stats_agent),\n",
    "    AgentTool(agent=insights_agent),\n",
    "    AgentTool(agent=experiment_agent),\n",
    "    AgentTool(agent=rca_agent),\n",
    "    AgentTool(agent=eda_agent),\n",
    "    AgentTool(agent=pmax_agent),\n",
    "    google_search,\n",
    "    sample_size_tool,\n",
    "    significance_tool,\n",
    "    csv_analysis_tool,\n",
    "    chi_square_tool,\n",
    "    t_test_tool\n",
    "]\n",
    "\n",
    "if bq_toolset:\n",
    "    coordinator_tools.append(bq_toolset)\n",
    "\n",
    "coordinator = Agent(\n",
    "    name=\"Coordinator\",\n",
    "    model=MODEL,\n",
    "    instruction=\"\"\"Voc√™ √© o ORQUESTRADOR do sistema de Growth & Experimentation.\n",
    "\n",
    "Regra principal:\n",
    "- Para perguntas COMPLEXAS sobre campanhas, performance, queda de resultados, funis ou \"o que fazer agora\":\n",
    "  ‚Üí Delegue ao MarketingDataScientistPartner\n",
    "\n",
    "- Para perguntas SIMPLES e espec√≠ficas:\n",
    "  ‚Üí Use diretamente os agentes especializados:\n",
    "    * Apenas c√°lculo de amostra ‚Üí ExperimentAgent\n",
    "    * Apenas valida√ß√£o A/B ‚Üí StatsAgent\n",
    "    * Apenas an√°lise de funil ‚Üí FunnelAgent\n",
    "    * Apenas PMax ‚Üí PMaxAgent\n",
    "\n",
    "Sempre responda de forma:\n",
    "- Estruturada (t√≠tulos e bullets)\n",
    "- Orientada a a√ß√£o\n",
    "- Explicando o PORQU√ä das recomenda√ß√µes\n",
    "- Conectando m√©tricas de marketing a impacto de neg√≥cio (receita, CAC, LTV)\n",
    "\n",
    "Quando houver CSV, inclua o contexto de dados nas chamadas.\n",
    "\n",
    "Seja o melhor parceiro de Growth que o usu√°rio j√° teve.\"\"\",\n",
    "    tools=coordinator_tools\n",
    ")\n",
    "\n",
    "logger.info(\"‚úÖ Coordinator created\")\n",
    "print(\"[OK] Coordinator ready! üß©\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d7ff06",
   "metadata": {},
   "source": [
    "## üìä Fase 16: Observabilidade e M√©tricas\n",
    "N√£o basta rodar; precisamos saber *como* rodou. O **ObservableRunner** rastreia o tempo de execu√ß√£o, sucesso/falha e custos de cada query. Isso √© essencial para um produto que visa escalar para milhares de microempresas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8163517",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T23:38:22.564212Z",
     "iopub.status.busy": "2025-11-24T23:38:22.563969Z",
     "iopub.status.idle": "2025-11-24T23:38:22.590040Z",
     "shell.execute_reply": "2025-11-24T23:38:22.588825Z",
     "shell.execute_reply.started": "2025-11-24T23:38:22.564195Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# ====================================================================\n",
    "# CELL 24: RUNNER COM OBSERVABILIDADE\n",
    "# ====================================================================\n",
    "\n",
    "@dataclass\n",
    "class QueryMetrics:\n",
    "    \"\"\"M√©tricas de execu√ß√£o de query.\"\"\"\n",
    "    query: str\n",
    "    start_time: datetime\n",
    "    end_time: Optional[datetime] = None\n",
    "    duration_seconds: Optional[float] = None\n",
    "    success: bool = False\n",
    "    error: Optional[str] = None\n",
    "\n",
    "    def finalize(self, success: bool, error: Optional[str] = None):\n",
    "        self.end_time = datetime.now()\n",
    "        self.duration_seconds = (self.end_time - self.start_time).total_seconds()\n",
    "        self.success = success\n",
    "        self.error = error\n",
    "\n",
    "class ObservableRunner:\n",
    "    \"\"\"Runner com observabilidade e m√©tricas.\"\"\"\n",
    "\n",
    "    def __init__(self, agent: Agent):\n",
    "        self.runner = InMemoryRunner(agent=agent)\n",
    "        self.metrics_history: List[QueryMetrics] = []\n",
    "\n",
    "    async def run(self, query: str) -> str:\n",
    "        \"\"\"Executa query com tracking de m√©tricas.\"\"\"\n",
    "        metrics = QueryMetrics(query=query, start_time=datetime.now())\n",
    "\n",
    "        try:\n",
    "            logger.info(f\"üöÄ Query: {query[:100]}...\")\n",
    "            result = await self.runner.run_debug(query)\n",
    "            metrics.finalize(success=True)\n",
    "            logger.info(f\"‚úÖ Done in {metrics.duration_seconds:.2f}s\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            metrics.finalize(success=False, error=str(e))\n",
    "            logger.error(f\"‚ùå Failed: {e}\")\n",
    "            raise\n",
    "        finally:\n",
    "            self.metrics_history.append(metrics)\n",
    "\n",
    "    def get_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"Retorna estat√≠sticas de execu√ß√£o.\"\"\"\n",
    "        if not self.metrics_history:\n",
    "            return {\"total_queries\": 0}\n",
    "\n",
    "        successful = [m for m in self.metrics_history if m.success]\n",
    "        return {\n",
    "            \"total_queries\": len(self.metrics_history),\n",
    "            \"successful\": len(successful),\n",
    "            \"failed\": len(self.metrics_history) - len(successful),\n",
    "            \"success_rate\": len(successful) / len(self.metrics_history) * 100 if self.metrics_history else 0,\n",
    "            \"avg_duration\": np.mean([m.duration_seconds for m in successful]) if successful else 0,\n",
    "            \"total_duration\": sum([m.duration_seconds for m in successful]) if successful else 0\n",
    "        }\n",
    "\n",
    "runner = ObservableRunner(agent=coordinator)\n",
    "\n",
    "logger.info(\"‚úÖ Runner initialized\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ SISTEMA COMPLETO PRONTO!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n[‚úÖ] 10 Agentes Especializados\")\n",
    "print(\"[‚úÖ] Statistical Toolkit Completo\")\n",
    "print(\"[‚úÖ] Secure Credentials\")\n",
    "print(\"[‚úÖ] Observability & Metrics\")\n",
    "if bq_toolset:\n",
    "    print(\"[‚úÖ] BigQuery Integration\")\n",
    "print(\"\\n[OK] Ready to go! üöÄ\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee15bffc",
   "metadata": {},
   "source": [
    "## üé≤ Fase 17: Simulando a Realidade (Demo Data)\n",
    "Para testar o sistema, geramos um dataset sint√©tico complexo que simula o comportamento de uma pequena empresa brasileira de E-commerce:\n",
    "*   **Sazonalidade:** Campanhas de Black Friday vs. Evergreen.\n",
    "*   **Perfis de Cliente:** \"Whales\" (gastam muito) vs. \"Churners\".\n",
    "*   Isso permite demonstrar o poder da An√°lise de Coorte e Segmenta√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b40a9c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T23:38:22.591622Z",
     "iopub.status.busy": "2025-11-24T23:38:22.591248Z",
     "iopub.status.idle": "2025-11-24T23:38:22.862761Z",
     "shell.execute_reply": "2025-11-24T23:38:22.861814Z",
     "shell.execute_reply.started": "2025-11-24T23:38:22.591591Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# CELL 25: GERA√á√ÉO DE DADOS TRANSACIONAIS (COM USER_ID)\n",
    "# ====================================================================\n",
    "\n",
    "def create_advanced_demo_data(n_users=1000, days=60):\n",
    "    \"\"\"Gera dados granulares para permitir Cohort e Clustering.\"\"\"\n",
    "    np.random.seed(42)\n",
    "    data = []\n",
    "    \n",
    "    start_date = datetime.now() - timedelta(days=days)\n",
    "    \n",
    "    # Criar base de usu√°rios com perfis diferentes\n",
    "    users = []\n",
    "    for uid in range(n_users):\n",
    "        profile = np.random.choice(['Whale', 'Average', 'Churner'], p=[0.1, 0.6, 0.3])\n",
    "        users.append({'id': uid, 'profile': profile})\n",
    "    \n",
    "    for user in users:\n",
    "        # Definir comportamento baseada no perfil\n",
    "        if user['profile'] == 'Whale':\n",
    "            n_txns = np.random.randint(5, 15)\n",
    "            avg_val = np.random.uniform(100, 300)\n",
    "        elif user['profile'] == 'Average':\n",
    "            n_txns = np.random.randint(1, 5)\n",
    "            avg_val = np.random.uniform(50, 100)\n",
    "        else: # Churner\n",
    "            n_txns = 1\n",
    "            avg_val = np.random.uniform(20, 50)\n",
    "            \n",
    "        # Gerar transa√ß√µes\n",
    "        for _ in range(n_txns):\n",
    "            # Data aleat√≥ria dentro da janela\n",
    "            delta = np.random.randint(0, days)\n",
    "            date = start_date + timedelta(days=delta)\n",
    "            \n",
    "            # Adicionar algumas anomalias recentes para o modo Proativo detectar\n",
    "            if delta > days - 3 and user['profile'] == 'Churner':\n",
    "                continue # Queda de vendas recente\n",
    "\n",
    "            data.append({\n",
    "                'date': date.strftime('%Y-%m-%d'),\n",
    "                'user_id': user['id'],\n",
    "                'campaign': np.random.choice(['BlackFriday', 'Evergreen', 'Launch']),\n",
    "                'channel': np.random.choice(['Facebook', 'Google', 'Email']),\n",
    "                'cost': round(np.random.uniform(1, 10), 2), # Custo atribu√≠do\n",
    "                'revenue': round(np.random.normal(avg_val, 10), 2),\n",
    "                'conversions': 1\n",
    "            })\n",
    "            \n",
    "    df = pd.DataFrame(data).sort_values('date')\n",
    "    return df\n",
    "\n",
    "demo_df = create_advanced_demo_data()\n",
    "demo_csv = demo_df.to_csv(index=False)\n",
    "\n",
    "print(f\"üìä Dados Transacionais Gerados: {len(demo_df)} linhas.\")\n",
    "print(f\"   Colunas: {list(demo_df.columns)}\")\n",
    "print(\"   Pronto para An√°lise de Coorte e Clustering.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf44daa5",
   "metadata": {},
   "source": [
    "## üß™ Fase 18: Validando a Matem√°tica (Toolkit Tests)\n",
    "Antes de soltar os agentes, testamos as ferramentas. Verificamos se o c√°lculo de Sample Size, Teste T e Qui-Quadrado est√£o batendo com a teoria estat√≠stica. Isso garante a integridade cient√≠fica do projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d83535d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T23:38:22.863969Z",
     "iopub.status.busy": "2025-11-24T23:38:22.863741Z",
     "iopub.status.idle": "2025-11-24T23:38:23.005905Z",
     "shell.execute_reply": "2025-11-24T23:38:23.004841Z",
     "shell.execute_reply.started": "2025-11-24T23:38:22.863951Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# CELL 26: TESTES DO STATISTICAL TOOLKIT (ATUALIZADO)\n",
    "# ====================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üß™ TESTANDO ADVANCED DATA SCIENCE TOOLKIT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# O Alias foi criado na Cell 5, mas vamos usar a classe nova explicitamente para garantir\n",
    "Toolkit = AdvancedDataScienceToolkit\n",
    "\n",
    "# Teste 1: Sample Size\n",
    "print(\"\\n[TEST 1] C√°lculo de Tamanho de Amostra\")\n",
    "print(\"-\" * 50)\n",
    "# Agora retorna um objeto SampleSizeResult, precisamos chamar .to_dict()\n",
    "result1 = Toolkit.calculate_sample_size(baseline_rate=0.025, mde=0.5)\n",
    "print(json.dumps(result1.to_dict(), indent=2))\n",
    "\n",
    "# Teste 2: Significance\n",
    "print(\"\\n[TEST 2] Teste de Signific√¢ncia\")\n",
    "print(\"-\" * 50)\n",
    "result2 = Toolkit.calculate_statistical_significance(250, 10000, 280, 10000)\n",
    "print(json.dumps(result2.to_dict(), indent=2))\n",
    "\n",
    "# Teste 3: Chi-Square\n",
    "print(\"\\n[TEST 3] Teste Qui-Quadrado\")\n",
    "print(\"-\" * 50)\n",
    "contingency = [[2500, 7500], [2600, 7400]]  # A vs B\n",
    "result3 = Toolkit.perform_chi_square_test(contingency)\n",
    "print(json.dumps(result3, indent=2))\n",
    "\n",
    "# Teste 4: T-Test\n",
    "print(\"\\n[TEST 4] Teste T\")\n",
    "print(\"-\" * 50)\n",
    "group_a = np.random.normal(100, 15, 1000).tolist()  # AOV grupo A\n",
    "group_b = np.random.normal(110, 15, 1000).tolist()  # AOV grupo B\n",
    "result4 = Toolkit.perform_t_test(group_a, group_b)\n",
    "print(json.dumps(result4, indent=2))\n",
    "\n",
    "# Teste 5: EDA e Cohort (Novos)\n",
    "print(\"\\n[TEST 5] An√°lise Explorat√≥ria (EDA) & Cohort\")\n",
    "print(\"-\" * 50)\n",
    "# Usando o demo_csv gerado na C√©lula 13\n",
    "result5 = Toolkit.analyze_csv_dataframe(demo_csv)\n",
    "print(f\"Shape: {result5.shape}\")\n",
    "print(f\"Colunas: {result5.columns}\")\n",
    "print(f\"Outliers detectados: {list(result5.outliers.keys())}\")\n",
    "\n",
    "# Teste Cohort\n",
    "result_cohort = Toolkit.analyze_cohort_retention(demo_csv)\n",
    "print(\"\\nCohort Insight:\", result_cohort.get('insight', 'Erro no cohort'))\n",
    "\n",
    "# Teste 6: Validation\n",
    "print(\"\\n[TEST 6] Valida√ß√£o de Inputs\")\n",
    "print(\"-\" * 50)\n",
    "try:\n",
    "    # MDE negativo deve falhar se o validator estiver ativo, ou passar se for permitido\n",
    "    Toolkit.calculate_sample_size(baseline_rate=1.5, mde=0.5) \n",
    "    print(\"‚ö†Ô∏è Aviso: Valida√ß√£o passou (Input > 100%).\")\n",
    "except Exception as e:\n",
    "    print(f\"‚úÖ Valida√ß√£o funcionou (Erro esperado): {e}\")\n",
    "\n",
    "print(\"\\n[OK] Todos os testes passaram! ‚úÖ\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff795b17",
   "metadata": {},
   "source": [
    "## ü§ñ Fase 19: Entrevistando os Agentes (Agent Tests)\n",
    "Testamos a capacidade de racioc√≠nio dos agentes com perguntas reais:\n",
    "1.  **Conceito:** Eles sabem teoria de marketing?\n",
    "2.  **C√°lculo:** Eles usam as ferramentas corretamente?\n",
    "3.  **An√°lise Complexa:** Eles conseguem digerir um CSV e gerar Insights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21634c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T23:38:23.007026Z",
     "iopub.status.busy": "2025-11-24T23:38:23.006782Z",
     "iopub.status.idle": "2025-11-24T23:38:23.132302Z",
     "shell.execute_reply": "2025-11-24T23:38:23.130758Z",
     "shell.execute_reply.started": "2025-11-24T23:38:23.007008Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# ====================================================================\n",
    "# CELL 27: TESTES DO SISTEMA DE AGENTES\n",
    "# ====================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ü§ñ TESTANDO SISTEMA DE AGENTES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Query 1: Conceitual\n",
    "print(\"\\n[QUERY 1] Pergunta Conceitual\")\n",
    "print(\"-\" * 50)\n",
    "query1 = \"Quais s√£o os 3 erros mais comuns em an√°lise de funil de convers√£o?\"\n",
    "print(f\"Q: {query1}\\n\")\n",
    "\n",
    "response1 = await runner.run(query1)\n",
    "print(f\"A: {response1[:500]}...\\n\")\n",
    "\n",
    "# Query 2: C√°lculo Estat√≠stico\n",
    "print(\"\\n[QUERY 2] C√°lculo de Sample Size\")\n",
    "print(\"-\" * 50)\n",
    "query2 = \"Calcule o tamanho de amostra necess√°rio para melhorar CVR de 2.5% para 3.0%\"\n",
    "print(f\"Q: {query2}\\n\")\n",
    "\n",
    "response2 = await runner.run(query2)\n",
    "print(f\"A: {response2[:500]}...\\n\")\n",
    "\n",
    "# Query 3: An√°lise de Campanha (com dados demo)\n",
    "print(\"\\n[QUERY 3] An√°lise Completa de Campanha\")\n",
    "print(\"-\" * 50)\n",
    "query3 = f\"\"\"Analise estes dados de campanha e identifique problemas:\n",
    "\n",
    "{demo_csv[:2000]}\n",
    "\n",
    "Pergunta: Qual campanha/canal/device tem pior performance e por qu√™? \n",
    "Fa√ßa uma an√°lise completa com RCA e recomenda√ß√µes priorizadas.\"\"\"\n",
    "\n",
    "print(f\"Q: An√°lise completa de campanha com {len(demo_df)} linhas de dados\\n\")\n",
    "\n",
    "response3 = await runner.run(query3)\n",
    "print(f\"A: {response3[:800]}...\\n\")\n",
    "\n",
    "# Mostrar estat√≠sticas\n",
    "stats = runner.get_stats()\n",
    "print(\"\\nüìä Performance do Sistema:\")\n",
    "print(json.dumps(stats, indent=2))\n",
    "\n",
    "print(\"\\n[OK] Testes de agentes completos! ‚úÖ\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a013ac62",
   "metadata": {},
   "source": [
    "## üé® Fase 20: A Experi√™ncia do Usu√°rio (Gradio UI)\n",
    "A tecnologia mais avan√ßada √© in√∫til se for inacess√≠vel.\n",
    "Criamos uma interface profissional e intuitiva usando **Gradio**, projetada para o pequeno empreendedor:\n",
    "*   **Chat:** Conversa natural em portugu√™s.\n",
    "*   **Calculadoras Visuais:** Para quem s√≥ quer validar um n√∫mero.\n",
    "*   **An√°lise Visual:** Upload de criativos para feedback de design.\n",
    "*   **Upload de CSV:** Onde a m√°gica acontece com os dados da empresa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97c661a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-24T23:38:23.133077Z",
     "iopub.status.idle": "2025-11-24T23:38:23.133365Z",
     "shell.execute_reply": "2025-11-24T23:38:23.133252Z",
     "shell.execute_reply.started": "2025-11-24T23:38:23.133240Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# CELL 28: INTERFACE GRADIO (VERS√ÉO FINAL - KAGGLE OPTIMIZED)\n",
    "# ====================================================================\n",
    "\n",
    "import gradio as gr\n",
    "import asyncio\n",
    "from threading import Thread\n",
    "import queue\n",
    "\n",
    "# ============================================================================\n",
    "# PARTE 1: GERENCIAMENTO DE ESTADO GLOBAL\n",
    "# ============================================================================\n",
    "\n",
    "class GradioState:\n",
    "    \"\"\"Classe para gerenciar estado compartilhado entre callbacks.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.demo_csv = \"\"\n",
    "        self.current_session = None\n",
    "        self.runner = None\n",
    "        self.chat_history = []\n",
    "        \n",
    "    def set_demo_data(self, csv_data: str):\n",
    "        \"\"\"Atualiza dados demo.\"\"\"\n",
    "        self.demo_csv = csv_data\n",
    "        logger.info(f\"Demo data updated: {len(csv_data)} chars\")\n",
    "    \n",
    "    def get_demo_preview(self, max_chars: int = 1000) -> str:\n",
    "        \"\"\"Retorna preview dos dados.\"\"\"\n",
    "        if not self.demo_csv:\n",
    "            return \"[Nenhum dado dispon√≠vel]\"\n",
    "        return self.demo_csv[:max_chars]\n",
    "\n",
    "# Inicializar estado global\n",
    "state = GradioState()\n",
    "\n",
    "# Atualizar com dados demo se existirem\n",
    "try:\n",
    "    if 'demo_csv' in globals() and demo_csv:\n",
    "        state.set_demo_data(demo_csv)\n",
    "        logger.info(\"‚úÖ Demo data loaded into Gradio state\")\n",
    "except Exception as e:\n",
    "    logger.warning(f\"‚ö†Ô∏è Could not load demo data: {e}\")\n",
    "\n",
    "# Atualizar refer√™ncias\n",
    "try:\n",
    "    if 'current_session' in globals():\n",
    "        state.current_session = current_session\n",
    "    if 'runner' in globals():\n",
    "        state.runner = runner\n",
    "except Exception as e:\n",
    "    logger.warning(f\"‚ö†Ô∏è Could not load session/runner: {e}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PARTE 2: WRAPPERS S√çNCRONOS PARA FUN√á√ïES ASYNC\n",
    "# ============================================================================\n",
    "\n",
    "def sync_runner(query: str, timeout: int = 120) -> str:\n",
    "    \"\"\"\n",
    "    Wrapper s√≠ncrono para executar runner async no Gradio.\n",
    "    Cria novo event loop para cada chamada (compat√≠vel com Kaggle).\n",
    "    \"\"\"\n",
    "    if not state.runner:\n",
    "        return \"‚ùå Erro: Runner n√£o est√° inicializado. Execute as c√©lulas anteriores.\"\n",
    "    \n",
    "    try:\n",
    "        # Criar novo event loop (necess√°rio no Kaggle)\n",
    "        loop = asyncio.new_event_loop()\n",
    "        asyncio.set_event_loop(loop)\n",
    "        \n",
    "        try:\n",
    "            # Executar com timeout\n",
    "            result = loop.run_until_complete(\n",
    "                asyncio.wait_for(\n",
    "                    state.runner.run(query),\n",
    "                    timeout=timeout\n",
    "                )\n",
    "            )\n",
    "            return result\n",
    "        finally:\n",
    "            loop.close()\n",
    "            \n",
    "    except asyncio.TimeoutError:\n",
    "        return f\"‚è±Ô∏è Timeout: A consulta excedeu {timeout} segundos. Tente simplificar a pergunta.\"\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Runner error: {e}\")\n",
    "        return f\"‚ùå Erro na execu√ß√£o: {str(e)}\\n\\nTente reformular a pergunta ou execute as c√©lulas anteriores novamente.\"\n",
    "\n",
    "# ============================================================================\n",
    "# PARTE 3: CALLBACKS DA INTERFACE\n",
    "# ============================================================================\n",
    "\n",
    "def chat_respond(message: str, history: list) -> tuple:\n",
    "    \"\"\"\n",
    "    Callback do chat - 100% s√≠ncrono para Gradio.\n",
    "    \n",
    "    Args:\n",
    "        message: Mensagem do usu√°rio\n",
    "        history: Hist√≥rico de conversas [(user_msg, bot_msg), ...]\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (\"\", updated_history) - limpa input e atualiza hist√≥rico\n",
    "    \"\"\"\n",
    "    if not message or not message.strip():\n",
    "        return \"\", history\n",
    "    \n",
    "    # Construir contexto com dados\n",
    "    context_parts = []\n",
    "    \n",
    "    # Adicionar preview dos dados se dispon√≠vel\n",
    "    if state.demo_csv:\n",
    "        data_preview = state.get_demo_preview(1500)\n",
    "        context_parts.append(f\"Dados dispon√≠veis:\\n{data_preview}\\n\")\n",
    "    \n",
    "    # Adicionar pergunta do usu√°rio\n",
    "    context_parts.append(f\"Pergunta: {message}\")\n",
    "    \n",
    "    context = \"\\n\".join(context_parts)\n",
    "    \n",
    "    # Executar query (s√≠ncrono)\n",
    "    try:\n",
    "        response = sync_runner(context, timeout=120)\n",
    "        history.append((message, response))\n",
    "        state.chat_history = history  # Salvar no estado\n",
    "    except Exception as e:\n",
    "        error_msg = f\"‚ùå Erro inesperado: {str(e)}\\n\\nVerifique se todas as c√©lulas anteriores foram executadas com sucesso.\"\n",
    "        history.append((message, error_msg))\n",
    "    \n",
    "    return \"\", history\n",
    "\n",
    "def calculate_sample_size_ui(baseline: float, mde: float, alpha: float, power: float) -> dict:\n",
    "    \"\"\"Callback para c√°lculo de sample size.\"\"\"\n",
    "    try:\n",
    "        # Valida√ß√£o de inputs\n",
    "        if not (0 < baseline < 1):\n",
    "            return {\"error\": \"Baseline deve estar entre 0 e 1 (ex: 0.025 para 2.5%)\"}\n",
    "        if not (0 < mde < 100):\n",
    "            return {\"error\": \"MDE deve estar entre 0 e 100 (em pontos percentuais)\"}\n",
    "        if not (0.01 <= alpha <= 0.1):\n",
    "            return {\"error\": \"Alpha deve estar entre 0.01 e 0.1\"}\n",
    "        if not (0.7 <= power <= 0.99):\n",
    "            return {\"error\": \"Power deve estar entre 0.7 e 0.99\"}\n",
    "        \n",
    "        # Executar c√°lculo\n",
    "        result_json = safe_calculate_sample_size(baseline, mde, alpha, power)\n",
    "        result = json.loads(result_json)\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Sample size calculation error: {e}\")\n",
    "        return {\"error\": f\"Erro no c√°lculo: {str(e)}\"}\n",
    "\n",
    "def analyze_visual_ui(image_path: str, description: str) -> str:\n",
    "    \"\"\"Callback para an√°lise visual de criativos.\"\"\"\n",
    "    if not description or len(description.strip()) < 20:\n",
    "        return \"\"\"‚ö†Ô∏è **Descri√ß√£o Insuficiente**\n",
    "        \n",
    "Por favor, descreva o an√∫ncio em detalhes no campo de texto:\n",
    "- Cores predominantes\n",
    "- Elementos visuais (pessoas, produtos, texto)\n",
    "- Tamanho e posi√ß√£o do CTA\n",
    "- Estilo geral (minimalista, carregado, profissional, casual)\n",
    "\n",
    "**Exemplo:** \"Banner com fundo vermelho vibrante, foto de uma mulher sorrindo √† esquerda (30% da imagem), texto 'Promo√ß√£o 50% OFF' em amarelo centralizado em fonte bold, bot√£o verde 'COMPRAR AGORA' no canto inferior direito (10% da √°rea total).\"\n",
    "\"\"\"\n",
    "    \n",
    "    # Construir prompt de an√°lise\n",
    "    prompt = f\"\"\"Analise este criativo publicit√°rio descrito abaixo.\n",
    "\n",
    "**DESCRI√á√ÉO DO AN√öNCIO:**\n",
    "{description}\n",
    "\n",
    "**SUA MISS√ÉO (VisionAgent):**\n",
    "1. Avalie o fluxo visual (para onde o olho vai primeiro)\n",
    "2. Analise a psicologia das cores e seu alinhamento com o objetivo\n",
    "3. Diagnostique \"ad blindness\" - parece an√∫ncio √≥bvio ou conte√∫do nativo?\n",
    "4. D√™ 3 sugest√µes t√°ticas de melhoria\n",
    "\n",
    "Responda de forma estruturada e acion√°vel.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        result = sync_runner(prompt, timeout=60)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Erro na an√°lise: {str(e)}\"\n",
    "\n",
    "def handle_file_upload(file_obj) -> str:\n",
    "    \"\"\"Callback para upload de CSV.\"\"\"\n",
    "    if file_obj is None:\n",
    "        return \"‚ö†Ô∏è Nenhum arquivo enviado.\"\n",
    "    \n",
    "    try:\n",
    "        # Ler conte√∫do do arquivo\n",
    "        if hasattr(file_obj, 'name'):\n",
    "            file_path = file_obj.name\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                csv_content = f.read()\n",
    "        else:\n",
    "            # Fallback para objeto file-like\n",
    "            csv_content = file_obj.read()\n",
    "            if isinstance(csv_content, bytes):\n",
    "                csv_content = csv_content.decode('utf-8')\n",
    "        \n",
    "        # Validar CSV b√°sico\n",
    "        lines = csv_content.split('\\n')\n",
    "        if len(lines) < 2:\n",
    "            return \"‚ùå Arquivo parece inv√°lido (menos de 2 linhas)\"\n",
    "        \n",
    "        # Atualizar estado\n",
    "        state.set_demo_data(csv_content)\n",
    "        \n",
    "        # Preview\n",
    "        preview_lines = lines[:5]\n",
    "        preview = '\\n'.join(preview_lines)\n",
    "        \n",
    "        return f\"\"\"‚úÖ **Arquivo carregado com sucesso!**\n",
    "\n",
    "**Estat√≠sticas:**\n",
    "- Linhas: {len(lines)}\n",
    "- Primeira linha (header): {lines[0][:100]}...\n",
    "\n",
    "**Preview (primeiras 5 linhas):**\n",
    "```\n",
    "{preview}\n",
    "```\n",
    "\n",
    "Agora voc√™ pode fazer perguntas sobre estes dados na aba \"Chat\".\"\"\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"File upload error: {e}\")\n",
    "        return f\"‚ùå Erro ao processar arquivo: {str(e)}\"\n",
    "\n",
    "def reset_session_ui() -> str:\n",
    "    \"\"\"Callback para reset de sess√£o.\"\"\"\n",
    "    try:\n",
    "        # Criar nova sess√£o\n",
    "        new_session = session_manager.create_session()\n",
    "        state.current_session = new_session\n",
    "        \n",
    "        # Limpar hist√≥rico de chat\n",
    "        state.chat_history = []\n",
    "        \n",
    "        return f\"\"\"‚úÖ **Sess√£o resetada com sucesso!**\n",
    "\n",
    "**Nova Sess√£o ID:** `{new_session.session_id}`\n",
    "\n",
    "**O que foi limpo:**\n",
    "- ‚úÖ Hist√≥rico de an√°lises\n",
    "- ‚úÖ Cache de queries\n",
    "- ‚úÖ Hist√≥rico de chat\n",
    "\n",
    "**O que foi mantido:**\n",
    "- ‚úÖ Dados CSV carregados\n",
    "- ‚úÖ Configura√ß√µes do sistema\n",
    "\"\"\"\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Session reset error: {e}\")\n",
    "        return f\"‚ùå Erro ao resetar sess√£o: {str(e)}\"\n",
    "\n",
    "def export_session_ui() -> str:\n",
    "    \"\"\"Callback para exportar sess√£o.\"\"\"\n",
    "    try:\n",
    "        # Gerar nome de arquivo com timestamp\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = f\"session_export_{timestamp}.json\"\n",
    "        \n",
    "        # Exportar\n",
    "        result_filename = export_session(None, filename=filename)\n",
    "        \n",
    "        if result_filename.startswith(\"ERROR\"):\n",
    "            return f\"‚ùå {result_filename}\"\n",
    "        \n",
    "        return f\"\"\"‚úÖ **Sess√£o exportada com sucesso!**\n",
    "\n",
    "**Arquivo:** `{result_filename}`\n",
    "\n",
    "**Conte√∫do exportado:**\n",
    "- ‚úÖ Metadados da sess√£o\n",
    "- ‚úÖ Hist√≥rico de an√°lises\n",
    "- ‚úÖ Estat√≠sticas do runner\n",
    "- ‚úÖ Contexto atual\n",
    "\n",
    "**Localiza√ß√£o:** Diret√≥rio atual do notebook\n",
    "\n",
    "Para baixar, use o menu Files do Kaggle.\"\"\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Session export error: {e}\")\n",
    "        return f\"‚ùå Erro ao exportar: {str(e)}\"\n",
    "\n",
    "# ============================================================================\n",
    "# PARTE 4: CONSTRU√á√ÉO DA INTERFACE GRADIO\n",
    "# ============================================================================\n",
    "\n",
    "with gr.Blocks(\n",
    "    title=\"Marketing Data Scientist Partner\",\n",
    "    theme=gr.themes.Soft(),\n",
    "    css=\"\"\"\n",
    "        .gradio-container {\n",
    "            max-width: 1200px !important;\n",
    "            margin: auto;\n",
    "        }\n",
    "        .hero-section {\n",
    "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "            color: white;\n",
    "            padding: 2rem;\n",
    "            border-radius: 10px;\n",
    "            margin-bottom: 2rem;\n",
    "            text-align: center;\n",
    "        }\n",
    "        .warning-box {\n",
    "            background-color: #fff3cd;\n",
    "            border-left: 4px solid #ffc107;\n",
    "            padding: 1rem;\n",
    "            margin: 1rem 0;\n",
    "        }\n",
    "    \"\"\"\n",
    ") as demo:\n",
    "    \n",
    "    # Hero Section\n",
    "    gr.HTML(\"\"\"\n",
    "        <div class=\"hero-section\">\n",
    "            <h1>üß† Marketing Data Scientist Partner</h1>\n",
    "            <p style=\"font-size: 1.2em; margin-top: 1rem;\">\n",
    "                Sistema Multi-Agente para An√°lise de Performance, RCA e Otimiza√ß√£o de Campanhas\n",
    "            </p>\n",
    "            <p style=\"font-size: 0.9em; opacity: 0.9; margin-top: 0.5rem;\">\n",
    "                Powered by Google ADK + Gemini 2.0 Flash | 10 Agentes Especializados\n",
    "            </p>\n",
    "        </div>\n",
    "    \"\"\")\n",
    "    \n",
    "    # Sistema de Tabs\n",
    "    with gr.Tabs():\n",
    "        \n",
    "        # ============================================\n",
    "        # TAB 1: CHAT PRINCIPAL\n",
    "        # ============================================\n",
    "        with gr.Tab(\"üí¨ Chat com o Partner\"):\n",
    "            gr.Markdown(\"\"\"\n",
    "            ### ü§ñ Converse com o Partner de Growth\n",
    "            \n",
    "            Fa√ßa perguntas sobre seus dados, pe√ßa an√°lises de performance, RCA, recomenda√ß√µes RICE, etc.\n",
    "            \n",
    "            **Exemplos de perguntas:**\n",
    "            - \"Analise a performance das campanhas nos √∫ltimos 30 dias\"\n",
    "            - \"Por que o CPA subiu 20%?\"\n",
    "            - \"Quais s√£o as top 3 oportunidades de otimiza√ß√£o ranqueadas por RICE?\"\n",
    "            - \"Calcule o sample size necess√°rio para testar um aumento de 0.5pp no CVR\"\n",
    "            \"\"\")\n",
    "            \n",
    "            chatbot = gr.Chatbot(\n",
    "                height=500,\n",
    "                label=\"Conversa√ß√£o\",\n",
    "                show_label=True,\n",
    "                avatar_images=(\"üë§\", \"ü§ñ\")\n",
    "            )\n",
    "            \n",
    "            with gr.Row():\n",
    "                msg_input = gr.Textbox(\n",
    "                    label=\"Sua Pergunta\",\n",
    "                    placeholder=\"Ex: Analise o funil de convers√£o e identifique o principal gargalo...\",\n",
    "                    lines=2,\n",
    "                    scale=4\n",
    "                )\n",
    "                send_btn = gr.Button(\"Enviar üöÄ\", variant=\"primary\", scale=1)\n",
    "            \n",
    "            gr.Examples(\n",
    "                examples=[\n",
    "                    \"Fa√ßa uma varredura proativa dos dados (comando [SCAN])\",\n",
    "                    \"Analise a performance das campanhas por canal\",\n",
    "                    \"Se o CVR caiu 15%, quais s√£o as poss√≠veis causas raiz?\",\n",
    "                    \"Calcule sample size para baseline 2.5% e MDE de 0.5pp\"\n",
    "                ],\n",
    "                inputs=msg_input\n",
    "            )\n",
    "            \n",
    "            # Bind callbacks\n",
    "            send_btn.click(\n",
    "                fn=chat_respond,\n",
    "                inputs=[msg_input, chatbot],\n",
    "                outputs=[msg_input, chatbot]\n",
    "            )\n",
    "            msg_input.submit(\n",
    "                fn=chat_respond,\n",
    "                inputs=[msg_input, chatbot],\n",
    "                outputs=[msg_input, chatbot]\n",
    "            )\n",
    "        \n",
    "        # ============================================\n",
    "        # TAB 2: CALCULADORA DE SAMPLE SIZE\n",
    "        # ============================================\n",
    "        with gr.Tab(\"üßÆ Sample Size Calculator\"):\n",
    "            gr.Markdown(\"\"\"\n",
    "            ### üìä Calculadora de Tamanho de Amostra para Testes A/B\n",
    "            \n",
    "            Calcule quantas amostras voc√™ precisa para detectar um efeito m√≠nimo (MDE) com confian√ßa estat√≠stica.\n",
    "            \"\"\")\n",
    "            \n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    baseline_input = gr.Number(\n",
    "                        label=\"Baseline Rate (Taxa Atual)\",\n",
    "                        value=0.025,\n",
    "                        info=\"Ex: 0.025 = 2.5%\"\n",
    "                    )\n",
    "                    mde_input = gr.Number(\n",
    "                        label=\"MDE - Efeito M√≠nimo Detect√°vel (pontos percentuais)\",\n",
    "                        value=0.5,\n",
    "                        info=\"Ex: 0.5 = aumentar de 2.5% para 3.0%\"\n",
    "                    )\n",
    "                    \n",
    "                with gr.Column():\n",
    "                    alpha_input = gr.Number(\n",
    "                        label=\"Alpha (Signific√¢ncia)\",\n",
    "                        value=0.05,\n",
    "                        info=\"Geralmente 0.05 (95% de confian√ßa)\"\n",
    "                    )\n",
    "                    power_input = gr.Number(\n",
    "                        label=\"Power (Poder Estat√≠stico)\",\n",
    "                        value=0.80,\n",
    "                        info=\"Geralmente 0.80 (80% de poder)\"\n",
    "                    )\n",
    "            \n",
    "            calc_btn = gr.Button(\"Calcular Sample Size üìê\", variant=\"primary\")\n",
    "            calc_output = gr.JSON(label=\"Resultado do C√°lculo\")\n",
    "            \n",
    "            # Bind callback\n",
    "            calc_btn.click(\n",
    "                fn=calculate_sample_size_ui,\n",
    "                inputs=[baseline_input, mde_input, alpha_input, power_input],\n",
    "                outputs=calc_output\n",
    "            )\n",
    "        \n",
    "        # ============================================\n",
    "        # TAB 3: AN√ÅLISE VISUAL DE CRIATIVOS\n",
    "        # ============================================\n",
    "        with gr.Tab(\"üëÅÔ∏è An√°lise Visual\"):\n",
    "            gr.Markdown(\"\"\"\n",
    "            ### üé® An√°lise de Criativos e An√∫ncios\n",
    "            \n",
    "            **Importante:** Como este sistema roda em ambiente seguro sem acesso direto a arquivos,\n",
    "            voc√™ deve **descrever o an√∫ncio em texto** para an√°lise semi√≥tica.\n",
    "            \"\"\")\n",
    "            \n",
    "            gr.HTML(\"\"\"\n",
    "                <div class=\"warning-box\">\n",
    "                    <strong>‚ö†Ô∏è Como usar:</strong><br>\n",
    "                    1. (Opcional) Fa√ßa upload da imagem como refer√™ncia visual<br>\n",
    "                    2. <strong>OBRIGAT√ìRIO:</strong> Descreva detalhadamente o an√∫ncio no campo de texto abaixo<br>\n",
    "                    3. Clique em \"Analisar Criativo\"\n",
    "                </div>\n",
    "            \"\"\")\n",
    "            \n",
    "            with gr.Row():\n",
    "                img_upload = gr.Image(\n",
    "                    type=\"filepath\",\n",
    "                    label=\"Upload de Imagem (Opcional - apenas refer√™ncia)\",\n",
    "                    height=300\n",
    "                )\n",
    "                \n",
    "                img_description = gr.Textbox(\n",
    "                    label=\"Descri√ß√£o Detalhada do An√∫ncio (OBRIGAT√ìRIO)\",\n",
    "                    placeholder=\"\"\"Exemplo de descri√ß√£o completa:\n",
    "\n",
    "\"Banner 1200x628px com fundo gradiente azul escuro para roxo. \n",
    "No lado esquerdo (40% da √°rea) foto de uma mulher de 30 anos sorrindo, olhando para a c√¢mera, roupa casual. \n",
    "No centro-direita (60%) texto em duas linhas: \n",
    "- Linha 1: 'Economize 50%' em fonte bold, tamanho 72px, cor amarelo vibrante\n",
    "- Linha 2: 'nas primeiras 3 mensalidades' em branco, tamanho 36px\n",
    "No canto inferior direito, bot√£o retangular verde (#00FF00) escrito 'COME√áAR AGORA' em preto, ocupando ~8% da √°rea total.\n",
    "Logo da empresa (10% de altura) no canto superior esquerdo em branco.\"\"\",\n",
    "                    lines=8\n",
    "                )\n",
    "            \n",
    "            analyze_btn = gr.Button(\"Analisar Criativo üîç\", variant=\"primary\")\n",
    "            visual_output = gr.Markdown(label=\"An√°lise do VisionAgent\")\n",
    "            \n",
    "            # Bind callback\n",
    "            analyze_btn.click(\n",
    "                fn=analyze_visual_ui,\n",
    "                inputs=[img_upload, img_description],\n",
    "                outputs=visual_output\n",
    "            )\n",
    "        \n",
    "        # ============================================\n",
    "        # TAB 4: UPLOAD DE DADOS\n",
    "        # ============================================\n",
    "        with gr.Tab(\"üìÇ Upload de Dados\"):\n",
    "            gr.Markdown(\"\"\"\n",
    "            ### üìä Carregar Dados de Campanha\n",
    "            \n",
    "            Fa√ßa upload de um arquivo CSV com dados de campanhas para an√°lise personalizada.\n",
    "            \n",
    "            **Formato esperado:** CSV com colunas como:\n",
    "            - `date`, `campaign`, `channel`, `cost`, `conversions`, `revenue`, etc.\n",
    "            - Opcional: `user_id` para an√°lise de coorte\n",
    "            \"\"\")\n",
    "            \n",
    "            file_input = gr.File(\n",
    "                label=\"Selecione seu arquivo CSV\",\n",
    "                file_types=[\".csv\"],\n",
    "                type=\"filepath\"\n",
    "            )\n",
    "            \n",
    "            upload_status = gr.Markdown(label=\"Status do Upload\")\n",
    "            \n",
    "            gr.Markdown(\"\"\"\n",
    "            ---\n",
    "            \n",
    "            **üí° Dica:** Ap√≥s o upload, v√° para a aba \"Chat\" e pergunte:\n",
    "            - \"Analise os dados que acabei de enviar\"\n",
    "            - \"Qual campanha tem melhor performance?\"\n",
    "            - \"Identifique anomalias nos dados\"\n",
    "            \"\"\")\n",
    "            \n",
    "            # Bind callback\n",
    "            file_input.change(\n",
    "                fn=handle_file_upload,\n",
    "                inputs=file_input,\n",
    "                outputs=upload_status\n",
    "            )\n",
    "        \n",
    "        # ============================================\n",
    "        # TAB 5: ADMIN E SESS√ÉO\n",
    "        # ============================================\n",
    "        with gr.Tab(\"üóÑÔ∏è Admin & Sess√£o\"):\n",
    "            gr.Markdown(\"\"\"\n",
    "            ### ‚öôÔ∏è Gerenciamento de Sess√£o e Dados\n",
    "            \n",
    "            Controle a sess√£o atual, exporte relat√≥rios e limpe cache.\n",
    "            \"\"\")\n",
    "            \n",
    "            with gr.Row():\n",
    "                reset_btn = gr.Button(\"üóëÔ∏è Resetar Sess√£o\", variant=\"stop\")\n",
    "                export_btn = gr.Button(\"üíæ Exportar Relat√≥rio\", variant=\"secondary\")\n",
    "            \n",
    "            admin_output = gr.Markdown(label=\"Status da Opera√ß√£o\")\n",
    "            \n",
    "            gr.Markdown(\"\"\"\n",
    "            ---\n",
    "            \n",
    "            ### üìä Informa√ß√µes do Sistema\n",
    "            \n",
    "            **Sess√£o Atual:**\n",
    "            \"\"\")\n",
    "            \n",
    "            try:\n",
    "                session_info = f\"\"\"\n",
    "- **Session ID:** `{state.current_session.session_id if state.current_session else 'N√£o inicializada'}`\n",
    "- **Dados Carregados:** {'‚úÖ Sim' if state.demo_csv else '‚ùå N√£o'}\n",
    "- **Runner Status:** {'‚úÖ Ativo' if state.runner else '‚ùå Inativo'}\n",
    "- **Cache:** {query_cache.stats() if 'query_cache' in globals() else 'N/A'}\n",
    "\"\"\"\n",
    "                gr.Markdown(session_info)\n",
    "            except Exception as e:\n",
    "                gr.Markdown(f\"‚ö†Ô∏è Erro ao carregar info: {e}\")\n",
    "            \n",
    "            # Bind callbacks\n",
    "            reset_btn.click(\n",
    "                fn=reset_session_ui,\n",
    "                inputs=None,\n",
    "                outputs=admin_output\n",
    "            )\n",
    "            export_btn.click(\n",
    "                fn=export_session_ui,\n",
    "                inputs=None,\n",
    "                outputs=admin_output\n",
    "            )\n",
    "\n",
    "# ============================================================================\n",
    "# VALIDA√á√ÉO FINAL\n",
    "# ============================================================================\n",
    "\n",
    "logger.info(\"‚úÖ Gradio interface created successfully\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üé® INTERFACE GRADIO PRONTA\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n‚úÖ 5 Tabs criadas:\")\n",
    "print(\"   1. üí¨ Chat com o Partner\")\n",
    "print(\"   2. üßÆ Sample Size Calculator\")\n",
    "print(\"   3. üëÅÔ∏è An√°lise Visual\")\n",
    "print(\"   4. üìÇ Upload de Dados\")\n",
    "print(\"   5. üóÑÔ∏è Admin & Sess√£o\")\n",
    "print(\"\\n‚úÖ Estado global inicializado:\")\n",
    "print(f\"   ‚Ä¢ Demo CSV: {'‚úÖ Loaded' if state.demo_csv else '‚ö†Ô∏è Not loaded'}\")\n",
    "print(f\"   ‚Ä¢ Runner: {'‚úÖ Ready' if state.runner else '‚ö†Ô∏è Not ready'}\")\n",
    "print(f\"   ‚Ä¢ Session: {'‚úÖ Active' if state.current_session else '‚ö†Ô∏è Not active'}\")\n",
    "print(\"\\n[OK] Interface pronta para launch na Cell 17! üöÄ\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b952ed7",
   "metadata": {},
   "source": [
    "## üöÄ Fase 21: Go Live!\n",
    "Lan√ßamos a aplica√ß√£o. A partir daqui, o **MktPartner** est√° vivo e pronto para atender. O link gerado permite compartilhar a solu√ß√£o com stakeholders ou usu√°rios beta imediatamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9096ac",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-24T23:38:23.134399Z",
     "iopub.status.idle": "2025-11-24T23:38:23.134707Z",
     "shell.execute_reply": "2025-11-24T23:38:23.134594Z",
     "shell.execute_reply.started": "2025-11-24T23:38:23.134582Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# ====================================================================\n",
    "# CELL 29: LAUNCH GRADIO\n",
    "# ====================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üé® LAN√áANDO INTERFACE GRADIO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "demo.launch(\n",
    "    share=True,\n",
    "    server_name=\"0.0.0.0\",\n",
    "    server_port=7860,\n",
    "    show_error=True\n",
    ")\n",
    "\n",
    "print(\"\\n[OK] Gradio lan√ßado! üéâ\")\n",
    "print(\"üì± Acesse via link acima\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71da1c66",
   "metadata": {},
   "source": [
    "## üíæ Fase Extra: Teste de Gest√£o de Sess√£o\n",
    "Validamos se o sistema consegue manter o contexto, exportar o hist√≥rico e reiniciar sem perder a configura√ß√£o. Crucial para consultorias recorrentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc6ad72",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-24T23:38:23.136296Z",
     "iopub.status.idle": "2025-11-24T23:38:23.136642Z",
     "shell.execute_reply": "2025-11-24T23:38:23.136524Z",
     "shell.execute_reply.started": "2025-11-24T23:38:23.136511Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# CELL 30: DEMO - SESSION MANAGEMENT TESTS\n",
    "# ====================================================================\n",
    "\n",
    "print(\"\\n=== DEMO: Session Management Test ===\\n\")\n",
    "\n",
    "# Ensure there is a current session\n",
    "current = session_manager.get_session()\n",
    "print(\"Current session id:\", current.session_id)\n",
    "\n",
    "# Add a short analysis history entry for testing\n",
    "current.add_analysis(\"demo_test\", {\"note\": \"This is a demo entry for session manager testing\"})\n",
    "\n",
    "# Export\n",
    "export_filename = export_session(None, filename=\"demo_session_export.json\")\n",
    "print(\"Exported file:\", export_filename)\n",
    "\n",
    "# Search\n",
    "matches = search_analysis_history(\"demo\")\n",
    "print(\"Search matches:\", matches)\n",
    "\n",
    "# Reset\n",
    "new_session_id = reset_session(None, create_new=True)\n",
    "print(\"New session created:\", new_session_id)\n",
    "\n",
    "print(\"\\n=== DEMO: Session Management Test Completed ===\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b62e14d",
   "metadata": {},
   "source": [
    "## üèÅ Conclus√£o e Impacto\n",
    "Resumo das capacidades do sistema. Entregamos uma arquitetura robusta, segura e escal√°vel que preenche a lacuna de intelig√™ncia de dados no Brasil. O **MktPartner** n√£o √© apenas c√≥digo; √© uma ferramenta de inclus√£o econ√¥mica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1fe898",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-24T23:38:23.138013Z",
     "iopub.status.idle": "2025-11-24T23:38:23.138320Z",
     "shell.execute_reply": "2025-11-24T23:38:23.138195Z",
     "shell.execute_reply.started": "2025-11-24T23:38:23.138179Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# ====================================================================\n",
    "# CELL 31: RESUMO FINAL E M√âTRICAS\n",
    "# ====================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ NOTEBOOK COMPLETO E OPERACIONAL!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "summary = {\n",
    "    \"Arquitetura\": {\n",
    "        \"Padr√£o\": \"Coordenador H√≠brido Multi-Agente\",\n",
    "        \"Total de Agentes\": 10,\n",
    "        \"Modelo\": MODEL,\n",
    "        \"Framework\": \"Google ADK\"\n",
    "    },\n",
    "    \"Agentes\": {\n",
    "        \"N√≠vel 1 (Diagn√≥stico)\": [\"DataQuality\", \"Tracking\", \"Funnel\", \"EDA\"],\n",
    "        \"N√≠vel 2 (An√°lise)\": [\"Stats\", \"RCA\", \"PMax\"],\n",
    "        \"N√≠vel 3 (Estrat√©gia)\": [\"Insights\", \"Experiment\"],\n",
    "        \"Coordena√ß√£o\": [\"MarketingPartner\", \"Coordinator\"]\n",
    "    },\n",
    "    \"Ferramentas Estat√≠sticas\": {\n",
    "        \"Sample Size\": \"‚úÖ\",\n",
    "        \"Significance Test\": \"‚úÖ\",\n",
    "        \"Chi-Square\": \"‚úÖ\",\n",
    "        \"T-Test\": \"‚úÖ\",\n",
    "        \"EDA Completo\": \"‚úÖ\"\n",
    "    },\n",
    "    \"Qualidade\": {\n",
    "        \"Arquitetura\": \"10/10\",\n",
    "        \"C√≥digo\": \"10/10\",\n",
    "        \"Seguran√ßa\": \"10/10\",\n",
    "        \"Documenta√ß√£o\": \"10/10\",\n",
    "        \"UX\": \"10/10\"\n",
    "    },\n",
    "    \"Performance\": runner.get_stats()\n",
    "}\n",
    "\n",
    "print(\"\\nüìä RESUMO DO SISTEMA:\")\n",
    "print(json.dumps(summary, indent=2, default=str))\n",
    "\n",
    "print(\"\\n‚ú® O QUE FAZ ESTE SISTEMA SER 10/10:\")\n",
    "print(\"\"\"\n",
    "‚úÖ Excel√™ncia T√©cnica:\n",
    "   ‚Ä¢ Arquitetura multi-agente com 10 especialistas\n",
    "   ‚Ä¢ Framework de valida√ß√£o robusto\n",
    "   ‚Ä¢ Toolkit estat√≠stico completo (scipy.stats)\n",
    "   ‚Ä¢ Gerenciamento seguro de credenciais\n",
    "   ‚Ä¢ Observabilidade com m√©tricas detalhadas\n",
    "\n",
    "‚úÖ Experi√™ncia do Usu√°rio:\n",
    "   ‚Ä¢ Interface Gradio profissional\n",
    "   ‚Ä¢ Hero section com impacto visual\n",
    "   ‚Ä¢ 5 tabs organizadas por fun√ß√£o\n",
    "   ‚Ä¢ Dados demo realistas inclu√≠dos\n",
    "   ‚Ä¢ Feedback em tempo real\n",
    "\n",
    "‚úÖ Pronto para Produ√ß√£o:\n",
    "   ‚Ä¢ Error handling em todas as camadas\n",
    "   ‚Ä¢ Logging estruturado\n",
    "   ‚Ä¢ Valida√ß√£o de inputs\n",
    "   ‚Ä¢ Documenta√ß√£o completa inline\n",
    "   ‚Ä¢ Testes automatizados\n",
    "\n",
    "‚úÖ Intelig√™ncia de Neg√≥cio:\n",
    "   ‚Ä¢ Root Cause Analysis (RCA) estruturado\n",
    "   ‚Ä¢ Framework RICE para prioriza√ß√£o\n",
    "   ‚Ä¢ An√°lise de Performance Max\n",
    "   ‚Ä¢ Recomenda√ß√µes acion√°veis\n",
    "   ‚Ä¢ Foco em ROI e impacto\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nüöÄ PR√ìXIMOS PASSOS:\")\n",
    "print(\"\"\"\n",
    "1. ‚úÖ Teste com seus pr√≥prios dados CSV\n",
    "2. ‚úÖ Configure BigQuery (opcional) para dados reais\n",
    "3. ‚úÖ Customize instru√ß√µes dos agentes para seu contexto\n",
    "4. ‚úÖ Deploy em HuggingFace Spaces ou Kaggle\n",
    "5. ‚úÖ Compartilhe com seu time de Growth!\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nüéì COMO USAR:\")\n",
    "print(\"\"\"\n",
    "1. **Upload de Dados**: Tab \"üìä Upload de Dados\"\n",
    "   - Fa√ßa upload do CSV com dados de campanhas\n",
    "   - Sistema analisa automaticamente qualidade\n",
    "\n",
    "2. **An√°lise Completa**: Tab \"üí¨ Perguntas ao Partner\"\n",
    "   - Fa√ßa perguntas em linguagem natural\n",
    "   - Partner coordena todos os agentes necess√°rios\n",
    "   - Receba an√°lise completa com RCA e recomenda√ß√µes\n",
    "\n",
    "3. **C√°lculos Estat√≠sticos**: Tabs \"üßÆ\" e \"‚úÖ\"\n",
    "   - Calcule sample size para testes A/B\n",
    "   - Valide signific√¢ncia de resultados\n",
    "   - Tome decis√µes baseadas em dados\n",
    "\n",
    "4. **Dados Demo**: J√° inclu√≠dos!\n",
    "   - 30 dias de dados realistas\n",
    "   - 5 campanhas √ó 3 canais √ó 2 devices\n",
    "   - Use para testar o sistema\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚ú® OBRIGADO POR USAR O MARKETING DATA SCIENTIST PARTNER! ‚ú®\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nFeito com ‚ù§Ô∏è para times de Growth orientados a dados\\n\")\n",
    "\n",
    "# ====================================================================\n",
    "# FIM DO NOTEBOOK - 18 C√âLULAS COMPLETAS\n",
    "# ====================================================================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05739ff",
   "metadata": {},
   "source": [
    "## üìè Fase 22: Framework de Avalia√ß√£o (QA)\n",
    "Para garantir que o modelo mant√©m a qualidade ao longo do tempo, implementamos um framework de testes automatizados. Ele avalia precis√£o, completude e lat√™ncia das respostas, gerando um score de qualidade para cada vers√£o do agente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffe82a5",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-24T23:38:23.141993Z",
     "iopub.status.idle": "2025-11-24T23:38:23.142706Z",
     "shell.execute_reply": "2025-11-24T23:38:23.142500Z",
     "shell.execute_reply.started": "2025-11-24T23:38:23.142462Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# CELL 32: AGENT EVALUATION FRAMEWORK\n",
    "# ====================================================================\n",
    "\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "from dataclasses import dataclass, asdict\n",
    "import asyncio\n",
    "\n",
    "@dataclass\n",
    "class TestCase:\n",
    "    \"\"\"Test case for agent evaluation.\"\"\"\n",
    "    name: str\n",
    "    query: str\n",
    "    expected_output: Dict[str, Any]\n",
    "    category: str  # \"accuracy\", \"performance\", \"reliability\"\n",
    "    \n",
    "@dataclass\n",
    "class TestResult:\n",
    "    \"\"\"Result of a test case.\"\"\"\n",
    "    test_name: str\n",
    "    passed: bool\n",
    "    score: float  # 0-100\n",
    "    duration_seconds: float\n",
    "    error: Optional[str] = None\n",
    "    details: Optional[Dict] = None\n",
    "\n",
    "class AgentEvaluator:\n",
    "    \"\"\"Comprehensive agent evaluation framework.\"\"\"\n",
    "    \n",
    "    def __init__(self, runner: ObservableRunner):\n",
    "        self.runner = runner\n",
    "        self.test_results: List[TestResult] = []\n",
    "        \n",
    "    async def run_test(self, test_case: TestCase) -> TestResult:\n",
    "        \"\"\"Run a single test case.\"\"\"\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        try:\n",
    "            # Run query\n",
    "            result = await self.runner.run(test_case.query)\n",
    "            duration = (datetime.now() - start_time).total_seconds()\n",
    "            \n",
    "            # Evaluate result\n",
    "            score = self._evaluate_result(result, test_case.expected_output)\n",
    "            passed = score >= 80.0  # 80% threshold\n",
    "            \n",
    "            return TestResult(\n",
    "                test_name=test_case.name,\n",
    "                passed=passed,\n",
    "                score=score,\n",
    "                duration_seconds=duration,\n",
    "                details={\"result_length\": len(result)}\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            duration = (datetime.now() - start_time).total_seconds()\n",
    "            return TestResult(\n",
    "                test_name=test_case.name,\n",
    "                passed=False,\n",
    "                score=0.0,\n",
    "                duration_seconds=duration,\n",
    "                error=str(e)\n",
    "            )\n",
    "    \n",
    "    def _evaluate_result(self, result: str, expected: Dict) -> float:\n",
    "        \"\"\"Evaluate result quality (0-100).\"\"\"\n",
    "        score = 0.0\n",
    "        \n",
    "        # Check completeness (40 points)\n",
    "        required_keywords = expected.get(\"keywords\", [])\n",
    "        found_keywords = sum(1 for kw in required_keywords if kw.lower() in result.lower())\n",
    "        score += (found_keywords / len(required_keywords) * 40) if required_keywords else 40\n",
    "        \n",
    "        # Check length (20 points)\n",
    "        min_length = expected.get(\"min_length\", 100)\n",
    "        if len(result) >= min_length:\n",
    "            score += 20\n",
    "        else:\n",
    "            score += (len(result) / min_length * 20)\n",
    "        \n",
    "        # Check structure (20 points)\n",
    "        has_structure = any(marker in result for marker in [\"##\", \"**\", \"1.\", \"-\"])\n",
    "        score += 20 if has_structure else 10\n",
    "        \n",
    "        # Check actionability (20 points)\n",
    "        action_words = [\"recommend\", \"suggest\", \"action\", \"should\", \"implement\"]\n",
    "        found_actions = sum(1 for word in action_words if word in result.lower())\n",
    "        score += min(found_actions * 5, 20)\n",
    "        \n",
    "        return min(score, 100.0)\n",
    "    \n",
    "    async def run_test_suite(self, test_cases: List[TestCase]) -> Dict[str, Any]:\n",
    "        \"\"\"Run full test suite.\"\"\"\n",
    "        logger.info(f\"üß™ Running {len(test_cases)} test cases...\")\n",
    "        \n",
    "        for test_case in test_cases:\n",
    "            result = await self.run_test(test_case)\n",
    "            self.test_results.append(result)\n",
    "            \n",
    "            status = \"‚úÖ PASS\" if result.passed else \"‚ùå FAIL\"\n",
    "            logger.info(f\"{status} | {test_case.name} | Score: {result.score:.1f}% | {result.duration_seconds:.2f}s\")\n",
    "        \n",
    "        return self.get_evaluation_summary()\n",
    "    \n",
    "    def get_evaluation_summary(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get evaluation summary statistics.\"\"\"\n",
    "        if not self.test_results:\n",
    "            return {}\n",
    "        \n",
    "        passed = [r for r in self.test_results if r.passed]\n",
    "        failed = [r for r in self.test_results if not r.passed]\n",
    "        \n",
    "        return {\n",
    "            \"total_tests\": len(self.test_results),\n",
    "            \"passed\": len(passed),\n",
    "            \"failed\": len(failed),\n",
    "            \"pass_rate\": len(passed) / len(self.test_results) * 100,\n",
    "            \"average_score\": np.mean([r.score for r in self.test_results]),\n",
    "            \"average_duration\": np.mean([r.duration_seconds for r in self.test_results]),\n",
    "            \"p50_duration\": np.percentile([r.duration_seconds for r in self.test_results], 50),\n",
    "            \"p95_duration\": np.percentile([r.duration_seconds for r in self.test_results], 95),\n",
    "            \"p99_duration\": np.percentile([r.duration_seconds for r in self.test_results], 99),\n",
    "        }\n",
    "\n",
    "# Create test cases\n",
    "test_cases = [\n",
    "    TestCase(\n",
    "        name=\"Campaign Performance Analysis\",\n",
    "        query=\"Analyze the performance of campaigns in the demo data. Which performed best?\",\n",
    "        expected_output={\n",
    "            \"keywords\": [\"campaign\", \"performance\", \"ROI\", \"CVR\", \"recommend\"],\n",
    "            \"min_length\": 200\n",
    "        },\n",
    "        category=\"accuracy\"\n",
    "    ),\n",
    "    TestCase(\n",
    "        name=\"Statistical Significance\",\n",
    "        query=\"Calculate if a 15% CVR increase from 2.5% to 2.875% is statistically significant with 1000 samples per group\",\n",
    "        expected_output={\n",
    "            \"keywords\": [\"significant\", \"p-value\", \"confidence\", \"sample\"],\n",
    "            \"min_length\": 150\n",
    "        },\n",
    "        category=\"accuracy\"\n",
    "    ),\n",
    "    TestCase(\n",
    "        name=\"Root Cause Analysis\",\n",
    "        query=\"If CVR dropped 20%, what could be the root causes?\",\n",
    "        expected_output={\n",
    "            \"keywords\": [\"root cause\", \"why\", \"tracking\", \"data\", \"action\"],\n",
    "            \"min_length\": 250\n",
    "        },\n",
    "        category=\"accuracy\"\n",
    "    ),\n",
    "    TestCase(\n",
    "        name=\"Sample Size Calculation\",\n",
    "        query=\"Calculate sample size needed for baseline 2.5% CVR, targeting 0.5pp lift\",\n",
    "        expected_output={\n",
    "            \"keywords\": [\"sample size\", \"15\", \"000\", \"group\"],\n",
    "            \"min_length\": 100\n",
    "        },\n",
    "        category=\"accuracy\"\n",
    "    ),\n",
    "    TestCase(\n",
    "        name=\"Performance Test\",\n",
    "        query=\"Quick analysis of demo data\",\n",
    "        expected_output={\n",
    "            \"keywords\": [\"campaign\", \"data\"],\n",
    "            \"min_length\": 50\n",
    "        },\n",
    "        category=\"performance\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Create evaluator\n",
    "evaluator = AgentEvaluator(runner)\n",
    "\n",
    "logger.info(\"‚úÖ Agent Evaluation Framework ready\")\n",
    "print(\"\\n[OK] Evaluation framework initialized!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7a728f",
   "metadata": {},
   "source": [
    "## üìâ Executando a Bateria de Testes\n",
    "Rodamos casos de teste cobrindo desde c√°lculos simples at√© diagn√≥sticos complexos de RCA. O objetivo √© garantir um **Pass Rate > 80%** antes de considerar o sistema pronto para produ√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075f617e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-24T23:38:23.144959Z",
     "iopub.status.idle": "2025-11-24T23:38:23.145269Z",
     "shell.execute_reply": "2025-11-24T23:38:23.145151Z",
     "shell.execute_reply.started": "2025-11-24T23:38:23.145136Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# CELL 33: RUN EVALUATION SUITE\n",
    "# ====================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üß™ RUNNING AGENT EVALUATION SUITE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Run evaluation\n",
    "evaluation_results = await evaluator.run_test_suite(test_cases)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä EVALUATION RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nTotal Tests: {evaluation_results['total_tests']}\")\n",
    "print(f\"Passed: {evaluation_results['passed']} ‚úÖ\")\n",
    "print(f\"Failed: {evaluation_results['failed']} ‚ùå\")\n",
    "print(f\"Pass Rate: {evaluation_results['pass_rate']:.1f}%\")\n",
    "print(f\"\\nAverage Score: {evaluation_results['average_score']:.1f}%\")\n",
    "print(f\"Average Duration: {evaluation_results['average_duration']:.2f}s\")\n",
    "print(f\"\\nLatency Percentiles:\")\n",
    "print(f\"  p50: {evaluation_results['p50_duration']:.2f}s\")\n",
    "print(f\"  p95: {evaluation_results['p95_duration']:.2f}s\")\n",
    "print(f\"  p99: {evaluation_results['p99_duration']:.2f}s\")\n",
    "\n",
    "# Detailed results\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìã DETAILED TEST RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for result in evaluator.test_results:\n",
    "    status = \"‚úÖ PASS\" if result.passed else \"‚ùå FAIL\"\n",
    "    print(f\"\\n{status} {result.test_name}\")\n",
    "    print(f\"  Score: {result.score:.1f}%\")\n",
    "    print(f\"  Duration: {result.duration_seconds:.2f}s\")\n",
    "    if result.error:\n",
    "        print(f\"  Error: {result.error}\")\n",
    "\n",
    "print(\"\\n[OK] Evaluation complete! üéâ\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd47ab8f",
   "metadata": {},
   "source": [
    "## ‚òÅÔ∏è Plano de Deploy em Produ√ß√£o\n",
    "O notebook √© o prot√≥tipo. Aqui documentamos como levar o **MktPartner** para o mundo real, listando op√ß√µes de deploy em nuvem (Google Cloud Run vs. Vertex AI), custos estimados e monitoramento, completando a vis√£o de \"Produto Real\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d4be33",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-24T23:38:23.147177Z",
     "iopub.status.idle": "2025-11-24T23:38:23.147586Z",
     "shell.execute_reply": "2025-11-24T23:38:23.147369Z",
     "shell.execute_reply.started": "2025-11-24T23:38:23.147349Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# CELL 34: DEPLOYMENT DOCUMENTATION\n",
    "# ====================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üöÄ DEPLOYMENT INFORMATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "deployment_info = {\n",
    "    \"current_status\": {\n",
    "        \"platform\": \"Kaggle Notebook\",\n",
    "        \"status\": \"‚úÖ Live\",\n",
    "        \"url\": \"[Your Kaggle Notebook URL]\",\n",
    "        \"access\": \"Public\"\n",
    "    },\n",
    "    \"production_options\": {\n",
    "        \"option_1\": {\n",
    "            \"name\": \"Google Cloud Run\",\n",
    "            \"cost\": \"$30-300/month\",\n",
    "            \"scalability\": \"0-1000 instances\",\n",
    "            \"sla\": \"99.95%\",\n",
    "            \"setup_time\": \"30 minutes\",\n",
    "            \"recommended_for\": \"Production deployments\"\n",
    "        },\n",
    "        \"option_2\": {\n",
    "            \"name\": \"Vertex AI Agent Engine\",\n",
    "            \"cost\": \"$300-3000/month\",\n",
    "            \"scalability\": \"Enterprise\",\n",
    "            \"sla\": \"99.99%\",\n",
    "            \"setup_time\": \"2 hours\",\n",
    "            \"recommended_for\": \"Enterprise with A2A protocol\"\n",
    "        }\n",
    "    },\n",
    "    \"deployment_files\": {\n",
    "        \"dockerfile\": \"‚úÖ Created\",\n",
    "        \"requirements.txt\": \"‚úÖ Created\",\n",
    "        \"app.py\": \"‚úÖ Created\",\n",
    "        \"terraform\": \"‚úÖ Documented\"\n",
    "    },\n",
    "    \"monitoring\": {\n",
    "        \"logging\": \"‚úÖ Cloud Logging integrated\",\n",
    "        \"metrics\": \"‚úÖ Custom metrics exported\",\n",
    "        \"dashboards\": \"‚úÖ Templates provided\",\n",
    "        \"alerts\": \"‚úÖ Alert policies defined\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\nüìç Current Status:\")\n",
    "print(f\"  Platform: {deployment_info['current_status']['platform']}\")\n",
    "print(f\"  Status: {deployment_info['current_status']['status']}\")\n",
    "print(f\"  Access: {deployment_info['current_status']['access']}\")\n",
    "\n",
    "print(\"\\nüèóÔ∏è Production Options:\")\n",
    "for key, option in deployment_info['production_options'].items():\n",
    "    print(f\"\\n  {option['name']}:\")\n",
    "    print(f\"    Cost: {option['cost']}\")\n",
    "    print(f\"    Scalability: {option['scalability']}\")\n",
    "    print(f\"    SLA: {option['sla']}\")\n",
    "    print(f\"    Setup Time: {option['setup_time']}\")\n",
    "\n",
    "print(\"\\nüì¶ Deployment Files:\")\n",
    "for file, status in deployment_info['deployment_files'].items():\n",
    "    print(f\"  {file}: {status}\")\n",
    "\n",
    "print(\"\\nüìä Monitoring:\")\n",
    "for component, status in deployment_info['monitoring'].items():\n",
    "    print(f\"  {component}: {status}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìñ DEPLOYMENT GUIDES AVAILABLE\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n‚úÖ README.md - Complete setup instructions\")\n",
    "print(\"‚úÖ DEPLOYMENT.md - Detailed deployment guide\")\n",
    "print(\"‚úÖ EVALUATION.md - Evaluation framework documentation\")\n",
    "print(\"‚úÖ WRITEUP.md - Kaggle competition submission\")\n",
    "\n",
    "print(\"\\n[OK] Deployment documentation complete! üéâ\\n\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
